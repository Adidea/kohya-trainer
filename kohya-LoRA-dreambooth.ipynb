{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "[![visitor][visitor-badge]][visitor-stats] \n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "\n",
        "# **Kohya LoRA Dreambooth**\n",
        "A Colab Notebook For LoRA Training (Dreambooth Method)\n",
        "<!-- [visitor-badge]: https://visitor-badge.glitch.me/badge?page_id=linaqruf.lora-dreambooth -->\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Kohya%20LoRA%20Dreambooth&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Kohya%20LoRA%20Dreambooth\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_6E01tRBfQU"
      },
      "source": [
        "| Notebook Name | Description | Link | V14 |\n",
        "| --- | --- | --- | --- |\n",
        "| [Kohya LoRA Dreambooth](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb) | LoRA Training (Dreambooth method) | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb) | [![](https://img.shields.io/static/v1?message=Older%20Version&logo=googlecolab&labelColor=5c5c5c&color=e74c3c&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/ff701379c65380c967cd956e4e9e8f6349563878/kohya-LoRA-dreambooth.ipynb) | \n",
        "| [Kohya LoRA Fine-Tuning](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-finetuner.ipynb) | LoRA Training (Fine-tune method) | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-finetuner.ipynb) | [![](https://img.shields.io/static/v1?message=Older%20Version&logo=googlecolab&labelColor=5c5c5c&color=e74c3c&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/ff701379c65380c967cd956e4e9e8f6349563878/kohya-LoRA-finetuner.ipynb) | \n",
        "| [Kohya Trainer](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer.ipynb) | Native Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer.ipynb) | [![](https://img.shields.io/static/v1?message=Older%20Version&logo=googlecolab&labelColor=5c5c5c&color=e74c3c&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/ff701379c65380c967cd956e4e9e8f6349563878/kohya-trainer.ipynb) | \n",
        "| [Cagliostro Colab UI](https://github.com/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui.ipynb) `NEW`| A Customizable Stable Diffusion Web UI| [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui.ipynb) | \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# I. Prepare Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "_u3q60di584x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2098451-55f3-4a1d-9076-1fcc7d78d1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/kohya-trainer'...\n",
            "remote: Enumerating objects: 2139, done.\u001b[K\n",
            "remote: Counting objects: 100% (807/807), done.\u001b[K\n",
            "remote: Compressing objects: 100% (232/232), done.\u001b[K\n",
            "remote: Total 2139 (delta 636), reused 660 (delta 575), pack-reused 1332\u001b[K\n",
            "Receiving objects: 100% (2139/2139), 3.80 MiB | 3.86 MiB/s, done.\n",
            "Resolving deltas: 100% (1391/1391), done.\n",
            "27 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 1,475 kB of archives.\n",
            "After this operation, 5,959 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libc-ares2 amd64 1.15.0-1ubuntu0.2 [36.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libaria2-0 amd64 1.35.0-1build1 [1,082 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 aria2 amd64 1.35.0-1build1 [356 kB]\n",
            "Fetched 1,475 kB in 2s (653 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 122531 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.15.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.15.0-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.35.0-1build1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.35.0-1build1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.35.0-1build1_amd64.deb ...\n",
            "Unpacking aria2 (1.35.0-1build1) ...\n",
            "Setting up libc-ares2:amd64 (1.15.0-1ubuntu0.2) ...\n",
            "Setting up libaria2-0:amd64 (1.35.0-1build1) ...\n",
            "Setting up aria2 (1.35.0-1build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.2/602.2 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for elfinder-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.4/150.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title ## 1.1. Install Kohya Trainer\n",
        "# @markdown Clone Kohya Trainer repository from GitHub and check for updates.\n",
        "# @markdown Use the text box below to switch to another branch or an old commit.\n",
        "# @markdown If left empty, it will default to the main branch.\n",
        "# @markdown This command will also install the necessary libraries.\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "import torch\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root_dir\n",
        "root_dir          = \"/content\"\n",
        "drive_dir         = os.path.join(root_dir, \"drive/MyDrive\")\n",
        "deps_dir          = os.path.join(root_dir, \"deps\")\n",
        "repo_dir          = os.path.join(root_dir, \"kohya-trainer\")\n",
        "training_dir      = os.path.join(root_dir, \"LoRA\")\n",
        "pretrained_model  = os.path.join(root_dir, \"pretrained_model\")\n",
        "vae_dir           = os.path.join(root_dir, \"vae\")\n",
        "config_dir        = os.path.join(training_dir, \"config\")\n",
        "tools_dir         = os.path.join(repo_dir, \"tools\")\n",
        "finetune_dir      = os.path.join(repo_dir, \"finetune\")\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "for store in [\"root_dir\", \"repo_dir\", \"training_dir\", \"pretrained_model\", \"vae_dir\", \"accelerate_config\", \"tools_dir\", \"finetune_dir\", \"config_dir\"]:\n",
        "    with capture.capture_output() as cap:\n",
        "        %store {store}\n",
        "        del cap\n",
        "\n",
        "repo_dict = {\n",
        "    \"Linaqruf/kohya-trainer (forked repo, stable, optimized for colab use)\" : \"https://github.com/Linaqruf/kohya-trainer\",\n",
        "    \"kohya-ss/sd-scripts (original repo, latest update)\"                    : \"https://github.com/kohya-ss/sd-scripts\",\n",
        "}\n",
        "\n",
        "repository        = \"Linaqruf/kohya-trainer (forked repo, stable, optimized for colab use)\" #@param [\"Linaqruf/kohya-trainer (forked repo, stable, optimized for colab use)\", \"kohya-ss/sd-scripts (original repo, latest update)\"] {allow-input: true}\n",
        "repo_url          = repo_dict[repository]\n",
        "branch            = \"dev\"  # @param {type: \"string\"}\n",
        "output_to_drive   = False  # @param {type: \"boolean\"}\n",
        "\n",
        "def clone_repo(url, branch):\n",
        "    if not os.path.exists(repo_dir):\n",
        "       !git clone -b {branch} {url} {repo_dir}\n",
        "\n",
        "def mount_drive(dir):\n",
        "    output_dir      = os.path.join(training_dir, \"output\")\n",
        "\n",
        "    if output_to_drive:\n",
        "        if not os.path.exists(drive_dir):\n",
        "            drive.mount(os.path.dirname(drive_dir))\n",
        "        output_dir  = os.path.join(drive_dir, \"kohya-trainer/output\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    global output_dir\n",
        "\n",
        "    output_dir      = mount_drive(drive_dir)\n",
        "    \n",
        "    for dir in [training_dir, config_dir, pretrained_model, vae_dir, output_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def install_dependencies():\n",
        "    requirements_file = os.path.join(repo_dir, \"requirements.txt\")\n",
        "    model_util        = os.path.join(repo_dir, \"library/model_util.py\")\n",
        "    gpu_info          = getoutput('nvidia-smi')\n",
        "    t4_xformers_wheel = \"https://github.com/Linaqruf/colab-xformers/releases/download/0.0.20/xformers-0.0.20+1d635e1.d20230519-cp310-cp310-linux_x86_64.whl\"\n",
        "\n",
        "    if 'T4' in gpu_info:\n",
        "        !sed -i \"s@cpu@cuda@\" {model_util}\n",
        "\n",
        "    !apt -y update -qq\n",
        "    !apt -y install aria2\n",
        "\n",
        "    !pip install -q --upgrade -r {requirements_file}\n",
        "\n",
        "    if '2.0.1+cu118' in torch.__version__:\n",
        "        if 'T4' in gpu_info:\n",
        "            !pip install -q {t4_xformers_wheel}\n",
        "        else:\n",
        "            !pip install -q torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "            !pip install -q xformers==0.0.19 triton==2.0.0 -U\n",
        "    else:\n",
        "        !pip install -q torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "        !pip install -q xformers==0.0.19 triton==2.0.0 -U\n",
        "        \n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "def prepare_environment():\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" \n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "    clone_repo(repo_url, branch)\n",
        "    os.chdir(repo_dir)\n",
        "    setup_directories()\n",
        "    install_dependencies()\n",
        "    prepare_environment()\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## 1.2. Get Pretrained Model\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import glob\n",
        "import gdown\n",
        "import requests\n",
        "import subprocess\n",
        "from IPython.utils import capture\n",
        "from urllib.parse import urlparse, unquote\n",
        "from pathlib import Path\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "\n",
        "model_url_or_path = \"Waifu Diffusion V1.5 Beta 3\" #@param [\"PASTE MODEL URL OR GDRIVE PATH HERE\", \"Anime Model\", \"Anything V3.1\", \"AnyLoRA\", \"ChilloutMix Ni\", \"Stable Diffusion V1.5\", \"Replicant V2\", \"Illuminati Diffusion V1.1\", \"Waifu Diffusion V1.5 Beta 3\", \"Stable Diffusion V2.1\"] {allow-input: true}\n",
        "vae_url_or_path   = \"Anime / Anything VAE\" #@param [\"PASTE VAE URL OR GDRIVE PATH HERE\", \"Anime / Anything VAE\", \"Blessed VAE\", \"Waifu Diffusion VAE\", \"Stable Diffusion VAE\"] {allow-input: true}\n",
        "\n",
        "available_models = {\n",
        "    # SDv1.x Pretrained Model\n",
        "    \"Anime Model\"                 : \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
        "    \"Anything V3.1\"               : \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "    \"AnyLoRA\"                     : \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_bakedVae_fp16_NOTpruned.safetensors\",\n",
        "    \"ChilloutMix Ni\"              : \"https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors\",\n",
        "    \"Stable Diffusion V1.5\"       : \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
        "    # SDv2.x Pretrained Model\n",
        "    \"Replicant V2\"                : \"https://huggingface.co/gsdf/Replicant-V2.0/resolve/main/Replicant-V2.0_fp32.safetensors\",\n",
        "    \"Illuminati Diffusion V1.1\"   : \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/illuminatiDiffusionV1_v11.safetensors\",\n",
        "    \"Waifu Diffusion V1.5 Beta 3\" : \"https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-beta3-base-fp16.safetensors\",\n",
        "    \"Stable Diffusion V2.1\"       : \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\n",
        "}\n",
        "\n",
        "available_vaes = {\n",
        "    \"Anime / Anything VAE\"        : \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "    \"Blessed VAE\"                 : \"https://huggingface.co/NoCrypt/blessed_vae/resolve/main/blessed2.vae.pt\",\n",
        "    \"Waifu Diffusion VAE\"         : \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "    \"Stable Diffusion VAE\"        : \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
        "}\n",
        "\n",
        "if model_url_or_path is not None:\n",
        "    valid_model_url = model_url_or_path\n",
        "    if model_url_or_path in available_models:\n",
        "        valid_model_url = available_models[model_url_or_path]\n",
        "\n",
        "if vae_url_or_path is not None:\n",
        "    valid_vae_url = vae_url_or_path\n",
        "    if vae_url_or_path in available_vaes:\n",
        "        valid_vae_url = available_vaes[vae_url_or_path]\n",
        "\n",
        "def get_supported_extensions():\n",
        "    return tuple([\".ckpt\", \".safetensors\", \".pt\", \".pth\"])\n",
        "\n",
        "def get_filename(url, quiet=True):\n",
        "    extensions = get_supported_extensions()\n",
        "\n",
        "    if url.startswith(drive_dir) or url.endswith(tuple(extensions)):\n",
        "        filename = os.path.basename(url)\n",
        "    else:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        if 'content-disposition' in response.headers:\n",
        "            content_disposition = response.headers['content-disposition']\n",
        "            filename = re.findall('filename=\"?([^\"]+)\"?', content_disposition)[0]\n",
        "        else:\n",
        "            url_path = urlparse(url).path\n",
        "            filename = unquote(os.path.basename(url_path))\n",
        "\n",
        "    if filename.endswith(tuple(get_supported_extensions())):\n",
        "        return filename\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def get_most_recent_file(directory):\n",
        "    files = glob.glob(os.path.join(directory, \"*\"))\n",
        "    if not files:\n",
        "        return None\n",
        "    most_recent_file = max(files, key=os.path.getmtime)\n",
        "    basename = os.path.basename(most_recent_file)\n",
        "\n",
        "    return most_recent_file\n",
        "\n",
        "def parse_args(config):\n",
        "    args = []\n",
        "\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args.append(f\"{v}\")\n",
        "        elif isinstance(v, str) and v is not None:\n",
        "            args.append(f'--{k}={v}')\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args.append(f\"--{k}\")\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args.append(f\"--{k}={v}\")\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args.append(f\"--{k}={v}\")\n",
        "\n",
        "    return args\n",
        "\n",
        "def aria2_download(dir, filename, url):\n",
        "    hf_token    = \"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\"\n",
        "    user_header = f\"Authorization: Bearer {hf_token}\"\n",
        "\n",
        "    aria2_config = {\n",
        "        \"console-log-level\"         : \"error\",\n",
        "        \"summary-interval\"          : 10,\n",
        "        \"header\"                    : user_header if \"huggingface.co\" in url else None,\n",
        "        \"continue\"                  : True,\n",
        "        \"max-connection-per-server\" : 16,\n",
        "        \"min-split-size\"            : \"1M\",\n",
        "        \"split\"                     : 16,\n",
        "        \"dir\"                       : dir,\n",
        "        \"out\"                       : filename,\n",
        "        \"_url\"                      : url,\n",
        "    }\n",
        "    aria2_args = parse_args(aria2_config)\n",
        "    subprocess.run([\"aria2c\", *aria2_args])\n",
        "\n",
        "def gdown_download(url, dst, filepath):\n",
        "    if \"/uc?id/\" in url:\n",
        "        return gdown.download(url, filepath, quiet=False)\n",
        "    elif \"/file/d/\" in url:\n",
        "        return gdown.download(url=url, output=filepath, quiet=False, fuzzy=True)\n",
        "    elif \"/drive/folders/\" in url:\n",
        "        os.chdir(dst)\n",
        "        return gdown.download_folder(url, quiet=True, use_cookies=False)\n",
        "\n",
        "def download(url, dst):\n",
        "    filename = get_filename(url, quiet=False)\n",
        "    filepath = os.path.join(dst, filename)\n",
        "    \n",
        "    if \"drive.google.com\" in url:\n",
        "        gdown = gdown_download(url, dst, filepath)\n",
        "    elif url.startswith(\"/content/drive/MyDrive/\"):\n",
        "        Path(filepath).write_bytes(Path(url).read_bytes())\n",
        "    else:\n",
        "        if \"huggingface.co\" in url:\n",
        "            if \"/blob/\" in url:\n",
        "                url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "        aria2_download(dst, filename, url)\n",
        "\n",
        "def get_filepath(url, dst):\n",
        "    extensions = get_supported_extensions()\n",
        "    filename = get_filename(url)\n",
        "    \n",
        "    if not filename.endswith(extensions):\n",
        "        most_recent_file = get_most_recent_file(dst)\n",
        "        filename = os.path.basename(most_recent_file)\n",
        "\n",
        "    filepath = os.path.join(dst, filename)\n",
        "\n",
        "    return filepath\n",
        "\n",
        "def main(): \n",
        "    global model_path, vae_path\n",
        "    \n",
        "    model_path = vae_path = None\n",
        "\n",
        "    download_targets = {\n",
        "        \"model\" : (valid_model_url, pretrained_model),\n",
        "        \"vae\"   : (valid_vae_url, vae_dir),\n",
        "    }\n",
        "    selected_files = {}\n",
        "    \n",
        "    for target, (url, dst) in download_targets.items():\n",
        "        if url and f\"PASTE {target.upper()} URL OR GDRIVE PATH HERE\" not in url:\n",
        "            download(url, dst)\n",
        "            selected_files[target] = get_filepath(url, dst)\n",
        "\n",
        "            if target == \"model\":\n",
        "                model_path = selected_files[\"model\"]\n",
        "            elif target == \"vae\":\n",
        "                vae_path = selected_files[\"vae\"]\n",
        "\n",
        "    for category, path in {\n",
        "        \"model\": model_path,\n",
        "        \"vae\": vae_path,\n",
        "    }.items():\n",
        "        if os.path.exists(path):\n",
        "            print(f\"Selected {category}: {path}\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "wrYGu-WxFbsq",
        "outputId": "392de5c9-41e6-4fd5-b7e2-db6e01a0b9a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected model: /content/pretrained_model/wd-beta3-base-fp16.safetensors\n",
            "Selected vae: /content/vae/animevae.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "kh7CeDqK4l3Y"
      },
      "outputs": [],
      "source": [
        "# @title ## 1.3. Directory Config\n",
        "# @markdown Specify the location of your training data in the following cell. A folder with the same name as your input will be created. `reg_data_dir` is optional and can be ignored.\n",
        "import os\n",
        "from IPython.utils import capture\n",
        "\n",
        "%store -r\n",
        "\n",
        "train_data_dir = \"/content/LoRA/train_data\"  # @param {type:'string'}\n",
        "reg_data_dir = \"\"  # @param {type:'string'}\n",
        "\n",
        "for dir in [train_data_dir, reg_data_dir]:\n",
        "    if dir:\n",
        "        with capture.capture_output() as cap:\n",
        "            os.makedirs(dir, exist_ok=True)\n",
        "            %store dir\n",
        "            del cap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## 1.4. Image Browser\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import portpicker\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from threading import Thread\n",
        "from imjoy_elfinder.app import main\n",
        "from google.colab.output import serve_kernel_port_as_iframe, serve_kernel_port_as_window\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown This cell allows you to view and manage your images in real-time. You can use it to:\n",
        "# @markdown - Prepare your dataset before training\n",
        "# @markdown - Monitor the sample outputs during training.\n",
        "\n",
        "root_dir      = \"/content\"\n",
        "browser_type  = \"sd-webui-infinite-image-browsing\" #@param [\"imjoy-elfinder\", \"sd-webui-infinite-image-browsing\"]\n",
        "window_height = 550 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "image_browser_url = \"https://github.com/zanllp/sd-webui-infinite-image-browsing.git\"\n",
        "image_browser_dir = os.path.join(root_dir, \"sd-webui-infinite-image-browsing\")\n",
        "main_app          = os.path.join(image_browser_dir, \"app.py\")\n",
        "config_file       = os.path.join(image_browser_dir, \"config.json\")\n",
        "port              = portpicker.pick_unused_port()\n",
        "\n",
        "config = {\n",
        "    \"outdir_txt2img_samples\": train_data_dir,\n",
        "}\n",
        "\n",
        "def clone(url, dir):\n",
        "    !git clone {url} {dir}\n",
        "\n",
        "def install_deps():\n",
        "    os.chdir(image_browser_dir)\n",
        "    !pip install -r {image_browser_dir}/requirements.txt\n",
        "\n",
        "def write_file(filename, config):\n",
        "    with open(filename, 'w',) as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "def run_app():\n",
        "    !python {main_app} --port={port} --sd_webui_config={config_file} > /dev/null 2>&1\n",
        "\n",
        "def launch():\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "    thread = Thread(target=main, args=[[f\"--root-dir={root_dir}\",\n",
        "                                        f\"--port={port}\",\n",
        "                                        f\"--thumbnail\"]])\n",
        "    \n",
        "    if browser_type == \"sd-webui-infinite-image-browsing\":\n",
        "        if not os.path.exists(image_browser_dir):\n",
        "            clone(image_browser_url, image_browser_dir)\n",
        "            install_deps()\n",
        "\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        os.chdir(train_data_dir)\n",
        "        write_file(config_file, config)\n",
        "        \n",
        "        thread = Thread(target=run_app)\n",
        "\n",
        "    thread.start()\n",
        "\n",
        "    serve_kernel_port_as_iframe(port, width='100%', height=window_height, cache_in_notebook=False)\n",
        "    \n",
        "    clear_output(wait=True)\n",
        "\n",
        "launch()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7gBCCYd8N5OS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "bbd87cbf-2bea-4c0d-8c56-ac2778189937"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(15512, \"/\", \"100%\", 550, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# II. Data Gathering\n",
        "\n",
        "You have three options for collecting your dataset:\n",
        "\n",
        "1. Upload it to Colab's local files.\n",
        "2. Use the `Simple Booru Scraper` to download images in bulk from Danbooru.\n",
        "3. Locate your dataset in Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "t17ZfiMB8GWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b41823d-b25c-47f4-90bf-a31c333e25b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " *** Download Progress Summary as of Sat May 20 01:10:27 2023 *** \n",
            "=\n",
            "[#417a6f 1.0GiB/1.0GiB(98%) CN:16 DL:120MiB]\n",
            "FILE: /content/zipfile.zip\n",
            "-\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "417a6f|\u001b[1;32mOK\u001b[0m  |    81MiB/s|/content/zipfile.zip\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Archive:  /content/zipfile.zip\n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/meta_cap.json  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/meta_cap_dd.json  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/meta_lat.json  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/meta_clean.json  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru087.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru024.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru020.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru054.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru076.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru004.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru008.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru036.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru072.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru008.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru055.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru094.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru018.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru086.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru058.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru043.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru048.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru081.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru015.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru013.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru045.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru050.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru022.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru081.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru025.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru062.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru018.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru076.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru094.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru010.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru023.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru017.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru086.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru066.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru078.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru054.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru017.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru050.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru007.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru001.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru065.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru065.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru057.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru038.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru036.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru061.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru007.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru032.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru098.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru063.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru029.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru091.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru077.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru043.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru051.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru009.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru042.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru026.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru080.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru059.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru074.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru081.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru047.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru020.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru052.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru003.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru094.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru058.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru033.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru031.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru008.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru096.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru078.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru069.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru048.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru001.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru087.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru010.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru069.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru065.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru075.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru050.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru059.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru090.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru064.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru010.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru015.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru056.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru096.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru031.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru039.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru022.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru065.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru034.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru080.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru006.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru002.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru089.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru010.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru040.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru081.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru019.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru026.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru035.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru003.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru068.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru092.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru040.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru063.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru096.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru071.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru048.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru085.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru093.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru026.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru061.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru076.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru041.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru001.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru088.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru011.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru075.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru032.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru079.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru031.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru075.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru044.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru021.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru013.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru005.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru086.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru083.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru084.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru054.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru051.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru016.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru066.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru042.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru071.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru042.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru028.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru084.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru082.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru041.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru045.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru014.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru009.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru091.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru002.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru050.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru094.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru013.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru039.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru046.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru049.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru091.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru088.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru079.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru030.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru002.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru026.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru087.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru095.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru098.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru074.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru056.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru046.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru042.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru079.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru095.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru046.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru019.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru044.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru011.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru023.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru073.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru089.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru077.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru096.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru027.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru018.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru028.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru013.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru047.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru059.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru038.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru039.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru033.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru057.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru008.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru035.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru005.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru083.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru078.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru011.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru053.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru017.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru027.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru082.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru060.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru018.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru077.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru040.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru095.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru004.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru055.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru097.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru014.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru084.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru047.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru075.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru036.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru033.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru058.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru064.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru060.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru037.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru039.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru063.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru061.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru066.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru012.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru024.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru015.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru007.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru031.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru088.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru092.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru012.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru085.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru016.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru040.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru053.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru019.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru068.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru091.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru098.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru014.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru006.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru037.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru078.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru063.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru071.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru029.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru060.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru098.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru064.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru051.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru068.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru045.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru037.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru020.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru073.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru051.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru084.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru069.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru038.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru085.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru083.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru012.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru095.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru057.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru090.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru004.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru092.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru049.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru054.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru021.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru062.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru016.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru097.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru045.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru052.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru032.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru083.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru047.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru025.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru009.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru044.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru061.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru072.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru049.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru055.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru006.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru060.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru093.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru052.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru025.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru034.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru004.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru030.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru090.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru021.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru089.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru077.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru070.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru064.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru024.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru082.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru001.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru015.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru080.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru009.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru088.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru068.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru041.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru052.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru022.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru043.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru062.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru062.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru025.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru043.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru003.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru034.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru076.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru034.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru070.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru058.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru029.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru002.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru030.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru030.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru056.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru069.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru074.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru067.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru093.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru023.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru020.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru041.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru012.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru072.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru071.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru005.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru021.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru005.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru066.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru053.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru074.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru032.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru082.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru059.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru093.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru067.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru067.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru007.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru080.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru072.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru087.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru023.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru037.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru053.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru085.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru006.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru003.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru011.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru056.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru027.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru022.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru017.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru016.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru028.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru073.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru079.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru049.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru038.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru055.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru097.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru019.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru048.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru070.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru067.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru089.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru028.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru024.png  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru086.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru097.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru092.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru070.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru090.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru035.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru035.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru057.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru044.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru029.caption  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru036.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru046.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru027.txt  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru033.jpg  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru073.npz  \n",
            " extracting: /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru014.caption  \n"
          ]
        }
      ],
      "source": [
        "# @title ## 2.1. Unzip Dataset\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "#@title ## Unzip Dataset\n",
        "# @markdown If your dataset is in a `zip` file and has been uploaded to a location, use this section to extract it. The dataset will be downloaded and automatically extracted to `train_data_dir` if `unzip_to` is empty.\n",
        "zipfile_url  = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-lora-dataset/resolve/main/hitokomoru_dataset.zip\" #@param {type:\"string\"}\n",
        "zipfile_name = \"zipfile.zip\"\n",
        "unzip_to     = \"\" #@param {type:\"string\"}\n",
        "\n",
        "hf_token     = \"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\"\n",
        "user_header  = f'\"Authorization: Bearer {hf_token}\"'\n",
        "\n",
        "if unzip_to:\n",
        "    os.makedirs(unzip_to, exist_ok=True)\n",
        "else:\n",
        "    unzip_to = train_data_dir\n",
        "\n",
        "def download_dataset(url):\n",
        "    if url.startswith(\"/content\"):\n",
        "        return url\n",
        "    elif \"drive.google.com\" in url:\n",
        "        os.chdir(root_dir)\n",
        "        !gdown --fuzzy {url}\n",
        "        return f\"{root_dir}/{zipfile_name}\"\n",
        "    elif \"huggingface.co\" in url:\n",
        "        if \"/blob/\" in url:\n",
        "            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {root_dir} -o {zipfile_name} {url}\n",
        "        return f\"{root_dir}/{zipfile_name}\"\n",
        "    else:\n",
        "        !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {root_dir} -o {zipfile_name} {url}\n",
        "        return f\"{root_dir}/{zipfile_name}\"\n",
        "\n",
        "def extract_dataset(zip_file, output_path):\n",
        "    !unzip -o {zip_file} -d \"{output_path}\"\n",
        "\n",
        "def remove_files(train_dir, files_to_move):\n",
        "    for filename in os.listdir(train_dir):\n",
        "        file_path = os.path.join(train_dir, filename)\n",
        "        if filename in files_to_move:\n",
        "            if not os.path.exists(file_path):\n",
        "                shutil.move(file_path, training_dir)\n",
        "            else:\n",
        "                os.remove(file_path)\n",
        "\n",
        "zip_file = download_dataset(zipfile_url)\n",
        "extract_dataset(zip_file, unzip_to)\n",
        "os.remove(zip_file)\n",
        "\n",
        "files_to_move = (\n",
        "    \"meta_cap.json\",\n",
        "    \"meta_cap_dd.json\",\n",
        "    \"meta_lat.json\",\n",
        "    \"meta_clean.json\",\n",
        ")\n",
        "\n",
        "remove_files(train_data_dir, files_to_move)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A0t1dfnU5Xkq"
      },
      "outputs": [],
      "source": [
        "#@title ## 2.2. Scrape Dataset\n",
        "import os\n",
        "import html\n",
        "from IPython.utils import capture\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "#@markdown Use `gallery-dl` to scrape images from an imageboard site. To specify `prompt(s)`, separate them with commas (e.g., `hito_komoru, touhou`).\n",
        "booru = \"Danbooru\" #@param [\"Danbooru\", \"Gelbooru\", \"Safebooru\"]\n",
        "prompt = \"hito_komoru\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Alternatively, you can provide a `custom_url` instead of using a predefined site.\n",
        "custom_url = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Use the `sub_folder` option to organize the downloaded images into separate folders based on their concept or category.\n",
        "sub_folder = \"\" #@param {type: \"string\"}\n",
        "\n",
        "user_agent = \"gdl/1.24.5\"\n",
        "\n",
        "#@markdown You can limit the number of images to download by using the `--range` option followed by the desired range (e.g., `1-200`).\n",
        "range = \"1-50\" #@param {type: \"string\"}\n",
        "\n",
        "write_tags = False #@param {type: \"boolean\"}\n",
        "\n",
        "additional_arguments = \"--filename /O --no-part\"\n",
        "\n",
        "tags = prompt.split(',')\n",
        "tags = '+'.join(tags)\n",
        "\n",
        "replacement_dict = {\" \": \"\", \"(\": \"%28\", \")\": \"%29\", \":\": \"%3a\"}\n",
        "tags = ''.join(replacement_dict.get(c, c) for c in tags)\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "if booru == \"Danbooru\":\n",
        "    url = \"https://danbooru.donmai.us/posts?tags={}\".format(tags)\n",
        "elif booru == \"Gelbooru\":\n",
        "    url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "else:\n",
        "    url = \"https://safebooru.org/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "\n",
        "valid_url = custom_url if custom_url else url\n",
        "\n",
        "def scrape(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "def pre_process_tags(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        item_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(item_path) and item.endswith(\".txt\"):\n",
        "            old_path = item_path\n",
        "            new_file_name = os.path.splitext(os.path.splitext(item)[0])[0] + \".txt\"\n",
        "            new_path = os.path.join(directory, new_file_name)\n",
        "\n",
        "            os.rename(old_path, new_path)\n",
        "\n",
        "            with open(new_path, \"r\") as f:\n",
        "                contents = f.read()\n",
        "\n",
        "            contents = html.unescape(contents)\n",
        "            contents = contents.replace(\"_\", \" \")\n",
        "            contents = \", \".join(contents.split(\"\\n\"))\n",
        "\n",
        "            with open(new_path, \"w\") as f:\n",
        "                f.write(contents)\n",
        "\n",
        "        elif os.path.isdir(item_path):\n",
        "            pre_process_tags(item_path)\n",
        "\n",
        "get_url_config = {\n",
        "    \"_valid_url\" : valid_url,\n",
        "    \"get-urls\" : True,\n",
        "    \"range\" : range if range else None,\n",
        "    \"user-agent\" : user_agent\n",
        "}\n",
        "\n",
        "scrape_config = {\n",
        "    \"_valid_url\" : valid_url,\n",
        "    \"directory\" : image_dir,\n",
        "    \"write-tags\" : write_tags,\n",
        "    \"range\" : range if range else None,\n",
        "    \"user-agent\" : user_agent\n",
        "}\n",
        "\n",
        "get_url_args = scrape(get_url_config)\n",
        "scrape_args = scrape(scrape_config)\n",
        "scraper_text = os.path.join(root_dir, \"scrape_this.txt\")\n",
        "\n",
        "if write_tags:\n",
        "    !gallery-dl {scrape_args} {additional_arguments}\n",
        "    pre_process_tags(train_data_dir)\n",
        "else:\n",
        "    with capture.capture_output() as cap:\n",
        "        !gallery-dl {get_url_args} {additional_arguments}\n",
        "    with open(scraper_text, \"w\") as f:\n",
        "        f.write(cap.stdout)\n",
        "\n",
        "    os.chdir(image_dir)\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -i {scraper_text}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-0qKyEgTchp"
      },
      "source": [
        "# III. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu"
      },
      "outputs": [],
      "source": [
        "# @title ## 3.1. Data Cleaning\n",
        "import os\n",
        "import random\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "#@markdown This section removes unsupported media types such as `.mp4`, `.webm`, and `.gif`, as well as any unnecessary files. \n",
        "#@markdown To convert a transparent dataset with an alpha channel (RGBA) to RGB and give it a white background, set the `convert` parameter to `True`.\n",
        "convert = False  # @param {type:\"boolean\"}\n",
        "#@markdown Alternatively, you can give the background a `random_color` instead of white by checking the corresponding option.\n",
        "random_color = False  # @param {type:\"boolean\"}\n",
        "recursive = False\n",
        " \n",
        "batch_size = 32\n",
        "supported_types = [\n",
        "    \".png\",\n",
        "    \".jpg\",\n",
        "    \".jpeg\",\n",
        "    \".webp\",\n",
        "    \".bmp\",\n",
        "    \".caption\",\n",
        "    \".npz\",\n",
        "    \".txt\",\n",
        "    \".json\",\n",
        "]\n",
        "\n",
        "background_colors = [\n",
        "    (255, 255, 255),\n",
        "    (0, 0, 0),\n",
        "    (255, 0, 0),\n",
        "    (0, 255, 0),\n",
        "    (0, 0, 255),\n",
        "    (255, 255, 0),\n",
        "    (255, 0, 255),\n",
        "    (0, 255, 255),\n",
        "]\n",
        "\n",
        "def clean_directory(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(file_path):\n",
        "            file_ext = os.path.splitext(item)[1]\n",
        "            if file_ext not in supported_types:\n",
        "                print(f\"Deleting file {item} from {directory}\")\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path) and recursive:\n",
        "            clean_directory(file_path)\n",
        "\n",
        "def process_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img_dir, image_name = os.path.split(image_path)\n",
        "\n",
        "    if img.mode in (\"RGBA\", \"LA\"):\n",
        "        if random_color:\n",
        "            background_color = random.choice(background_colors)\n",
        "        else:\n",
        "            background_color = (255, 255, 255)\n",
        "        bg = Image.new(\"RGB\", img.size, background_color)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            bg = bg.convert(\"RGB\")\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            bg.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            bg.save(image_path, \"PNG\")\n",
        "            print(f\" Converted image: {image_name}\")\n",
        "    else:\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            img.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            img.save(image_path, \"PNG\")\n",
        "\n",
        "def find_images(directory):\n",
        "    images = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\") or file.endswith(\".webp\"):\n",
        "                images.append(os.path.join(root, file))\n",
        "    return images\n",
        "\n",
        "clean_directory(train_data_dir)\n",
        "images = find_images(train_data_dir)\n",
        "num_batches = len(images) // batch_size + 1\n",
        "\n",
        "if convert:\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        for i in tqdm(range(num_batches)):\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "            batch = images[start:end]\n",
        "            executor.map(process_image, batch)\n",
        "\n",
        "    print(\"All images have been converted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdISafLeyklg"
      },
      "source": [
        "## 3.2. Data Captioning\n",
        "\n",
        "- For general images, use BLIP captioning. \n",
        "- For anime and manga-style images, use Waifu Diffusion 1.4 Tagger V2. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xvGx2Ikhc8iy"
      },
      "outputs": [],
      "source": [
        "#@title ### 3.2.1. BLIP Captioning\n",
        "#@markdown BLIP is a pre-training framework for unified vision-language understanding and generation, which achieves state-of-the-art results on a wide range of vision-language tasks. It can be used as a tool for image captioning, for example, `astronaut riding a horse in space`. \n",
        "import os\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "beam_search = True #@param {type:'boolean'}\n",
        "min_length = 5 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "max_length = 75 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"   : train_data_dir,\n",
        "    \"batch_size\"        : 8,\n",
        "    \"beam_search\"       : beam_search,\n",
        "    \"min_length\"        : min_length,\n",
        "    \"max_length\"        : max_length,\n",
        "    \"debug\"             : True,\n",
        "    \"caption_extension\" : \".caption\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"recursive\"         : True\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python make_captions.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "-BdXV7rAy2ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78143f17-aa45-4860-c139-3527546042b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading wd14 tagger model from hf_hub. id: SmilingWolf/wd-v1-4-convnextv2-tagger-v2\n",
            "Downloading keras_metadata.pb: 100% 477k/477k [00:00<00:00, 49.0MB/s]\n",
            "Downloading saved_model.pb: 100% 6.17M/6.17M [00:00<00:00, 220MB/s]\n",
            "Downloading (…)in/selected_tags.csv: 100% 254k/254k [00:00<00:00, 386kB/s]\n",
            "Downloading (…).data-00000-of-00001: 100% 388M/388M [00:01<00:00, 381MB/s]\n",
            "Downloading variables.index: 100% 25.5k/25.5k [00:00<00:00, 33.0MB/s]\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "found 98 images.\n",
            "  0% 0/13 [00:00<?, ?it/s]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru001.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, brown hair, gloves, long sleeves, green eyes, standing, jacket, full body, pantyhose, boots, parted lips, green hair, black gloves, grey background, black footwear, coat, black pantyhose, cloak, high collar, ankle boots\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru002.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, short hair, bangs, blue eyes, simple background, hair ornament, white background, jewelry, white hair, parted lips, horns, from side, bell, profile, piercing, portrait\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru003.jpg:\n",
            "  Character tags: cirno\n",
            "  General tags: 1girl, solo, looking at viewer, blush, smile, short hair, bangs, simple background, shirt, white background, bow, ribbon, hair between eyes, closed mouth, blue hair, white shirt, hair bow, wings, pointy ears, collared shirt, star (symbol), grey eyes, neck ribbon, blue bow, portrait, ice, ice wings\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru004.jpg:\n",
            "  Character tags: izayoi sakuya\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, white background, hair between eyes, upper body, braid, flower, white hair, grey hair, frills, parted lips, hair flower, pink eyes, mole, twin braids, from side, maid, maid headdress, mole under eye, profile, rose, portrait, black flower\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru005.jpg:\n",
            "  Character tags: avatar (ff14)\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, black hair, bow, animal ears, jewelry, closed mouth, upper body, flower, hair bow, grey hair, earrings, cat ears, pink eyes, hair over one eye, black bow, facial mark, eyes visible through hair, crescent, portrait, red background, blue flower, miqo'te\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru006.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, simple background, black hair, hair ornament, white background, flower, parted lips, japanese clothes, hair flower, blunt bangs, kimono, grey eyes, bell, mask, portrait, jingle bell, arrow (projectile), kanzashi\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru007.jpg:\n",
            "  Character tags: avatar (ff14)\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, white background, jewelry, grey hair, parted lips, horns, grey background, grey eyes, heterochromia, portrait, dragon horns, headpiece, au ra, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru008.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, blue eyes, blonde hair, simple background, shirt, white background, hair between eyes, closed mouth, blue hair, upper body, braid, flower, ahoge, multicolored hair, two-tone hair, single braid, portrait, blue flower\n",
            "  8% 1/13 [00:19<03:48, 19.08s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru009.jpg:\n",
            "  Character tags: avatar (ff14)\n",
            "  General tags: 1girl, solo, long hair, blue eyes, simple background, white background, animal ears, flower, parted lips, choker, rabbit ears, grey eyes, black choker, looking away, portrait, viera, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru010.jpg:\n",
            "  Character tags: avatar (ff14)\n",
            "  General tags: 1girl, solo, breasts, looking at viewer, short hair, bangs, hair ornament, white background, animal ears, hair between eyes, bare shoulders, purple eyes, tail, upper body, braid, parted lips, choker, cat ears, cat tail, facial mark, eyes visible through hair, portrait, miqo'te\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru011.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, bangs, blue eyes, simple background, hair ornament, white background, ribbon, pink hair, braid, parted lips, virtual youtuber, hood, portrait, fish, multicolored eyes\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru012.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, open mouth, bangs, simple background, hair ornament, white background, hair between eyes, monochrome, flower, white hair, greyscale, fang, hair flower, grey eyes, rose, portrait, skin fang, black flower, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru013.png:\n",
            "  Character tags: remilia scarlet\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hat, white background, dress, bow, ribbon, hair between eyes, blue hair, upper body, flower, white hair, multicolored hair, frills, parted lips, wings, hand up, pink eyes, white dress, red bow, red ribbon, fingernails, head tilt, torn clothes, ascot, capelet, floating hair, rose, white headwear, mob cap, hat ribbon, bat wings, light smile, white flower, slit pupils, red flower, wind, hat bow, portrait, red nails, bright pupils, white pupils, red rose, colored inner hair, hat flower, alternate eye color, red ascot, white capelet, white rose, white ascot\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru014.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, blush, bangs, simple background, black hair, white background, closed mouth, sidelocks, japanese clothes, kimono, grey background, hair bun, grey eyes, single hair bun, portrait\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru015.png:\n",
            "  Character tags: avatar (ff14)\n",
            "  General tags: 1girl, solo, long hair, looking at viewer, blue eyes, blonde hair, simple background, shirt, white background, animal ears, closed mouth, upper body, rabbit ears, ascot, red ascot, viera\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru016.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, hair between eyes, jewelry, closed mouth, green eyes, braid, flower, white hair, twin braids, ascot, blue background, portrait, white ascot, cropped shoulders\n",
            " 15% 2/13 [00:21<01:57, 10.64s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru017.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, skirt, simple background, shirt, hair ornament, long sleeves, white background, holding, standing, jacket, full body, yellow eyes, white shirt, braid, ahoge, white hair, pantyhose, hairband, boots, parted lips, shoes, glasses, collared shirt, black skirt, off shoulder, black footwear, vest, coat, black pantyhose, single braid, pale skin, fish, spot color, black vest\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru018.png:\n",
            "  Character tags: remilia scarlet\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, red eyes, hat, white background, hair between eyes, jewelry, flower, white hair, one eye closed, wings, pointy ears, from side, fingernails, ascot, eyelashes, floating hair, rose, white headwear, mob cap, bat wings, white flower, letterboxed, slit pupils, brooch, red flower, portrait, red nails, long fingernails, hat flower, white ascot\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru019.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, short hair, open mouth, bangs, simple background, hair ornament, white background, hair between eyes, purple eyes, flower, white hair, teeth, looking away, crown, portrait, purple flower, mini crown, mouse, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru020.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, bangs, blue eyes, simple background, hair ornament, white background, jewelry, upper body, flower, white hair, parted lips, hair flower, mole, from side, ascot, mole under eye, profile, looking up, portrait, white ascot\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru021.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, bangs, simple background, black hair, white background, purple eyes, sidelocks, parted lips, mole, from side, eyelashes, mole under eye, looking up, portrait\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru022.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, hair ornament, hair between eyes, jewelry, green eyes, upper body, parted lips, choker, hood, head tilt, black choker, ring, hood down, black background\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru023.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, blue eyes, simple background, hair ornament, white background, grey hair, parted lips, looking back, from behind, grey eyes, own hands together, portrait, fish\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru024.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, skirt, simple background, black hair, long sleeves, white background, holding, animal ears, closed mouth, standing, full body, yellow eyes, pleated skirt, japanese clothes, socks, cat ears, wide sleeves, black skirt, kimono, bell, sandals, white socks, jingle bell, extra ears, fish, tabi, zouri\n",
            " 23% 3/13 [00:23<01:19,  7.93s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru025.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, open mouth, bangs, hair ornament, gloves, green eyes, upper body, flower, multicolored hair, white gloves, from side, black background, portrait, black flower\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru026.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, open mouth, bangs, blonde hair, simple background, hair ornament, white background, bow, holding, hair between eyes, jewelry, earrings, pink eyes, plaid, stuffed toy, stuffed animal, crown, portrait, teddy bear, holding stuffed toy\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru027.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, white background, hair between eyes, pink hair, white hair, parted lips, pink eyes, grey eyes, floating hair, portrait, close-up, white eyes\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru028.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, white background, jewelry, upper body, flower, white hair, hairband, parted lips, hair flower, hair over one eye, grey eyes, ascot, rose, black hairband, brooch, portrait, white ascot, black flower, black rose, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru029.jpg:\n",
            "  Character tags: komeiji koishi\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, shirt, hat, white background, bow, green eyes, upper body, frills, parted lips, black headwear, hat bow, third eye, portrait, yellow bow, yellow shirt, eyeball\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru030.jpg:\n",
            "  Character tags: komeiji satori\n",
            "  General tags: 1girl, solo, short hair, bangs, simple background, shirt, hair ornament, white background, closed mouth, purple eyes, upper body, pink hair, heart, hairband, frills, buttons, expressionless, eyes visible through hair, black hairband, blue shirt, blouse, third eye, frilled shirt collar, heart hair ornament, eyeball, heart button\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru031.jpg:\n",
            "  Character tags: kaenbyou rin\n",
            "  General tags: 1girl, solo, breasts, looking at viewer, bangs, red eyes, long sleeves, dress, bow, animal ears, tail, upper body, braid, hair bow, red hair, frills, parted lips, choker, puffy sleeves, cat ears, hand up, blunt bangs, black dress, from side, cat tail, animal ear fluff, black bow, black choker, juliet sleeves, multiple tails, extra ears, chromatic aberration, two tails, nekomata\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru032.jpg:\n",
            "  Character tags: komeiji koishi\n",
            "  General tags: 1girl, solo, looking at viewer, smile, short hair, bangs, shirt, hat, white background, bow, hair between eyes, closed mouth, green eyes, upper body, frills, green hair, black headwear, hat bow, third eye, yellow bow, frilled shirt collar, yellow shirt\n",
            " 31% 4/13 [00:25<00:56,  6.29s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru033.jpg:\n",
            "  Character tags: izayoi sakuya\n",
            "  General tags: 1girl, solo, breasts, looking at viewer, short hair, bangs, blue eyes, simple background, shirt, gloves, white background, dress, bow, ribbon, holding, jewelry, medium breasts, white shirt, upper body, weapon, braid, white hair, short sleeves, hair bow, grey hair, frills, parted lips, puffy sleeves, white gloves, hand up, grey background, holding weapon, apron, twin braids, puffy short sleeves, maid, maid headdress, neck ribbon, blue dress, knife, brooch, waist apron, white apron, green bow, petticoat, chromatic aberration, holding knife, back bow, between fingers\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru034.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, gloves, long sleeves, white background, dress, bow, closed mouth, purple eyes, upper body, flower, white hair, short sleeves, hairband, frills, puffy sleeves, white gloves, hand up, hair flower, apron, black dress, from side, head tilt, looking to the side, maid, maid headdress, rose, juliet sleeves, waist apron, white apron, hand on own face, frilled apron, hand on own cheek, back bow, layered sleeves, black flower, black rose\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru035.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, shirt, hair ornament, white background, white shirt, flower, grey hair, parted lips, collared shirt, hair flower, grey eyes, maid headdress, rose, eyes visible through hair, wing collar, portrait, black flower, black rose, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru036.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, bangs, simple background, shirt, hair ornament, gloves, long sleeves, white background, ribbon, sitting, closed mouth, monochrome, upper body, white hair, virtual youtuber, white gloves, hand up, hair bun, hair over one eye, cup, neck ribbon, chair, holding cup, spot color, teacup, head rest\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru037.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, short hair, bangs, blonde hair, simple background, black hair, hair ornament, gloves, long sleeves, dress, bow, closed mouth, green eyes, upper body, flower, multicolored hair, frills, green hair, puffy sleeves, white gloves, hair flower, apron, black dress, two-tone hair, maid, hands up, maid headdress, rose, juliet sleeves, black background, waist apron, white apron, maid apron, frilled apron, colored inner hair, black flower, black rose\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru038.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, long sleeves, white background, dress, bow, closed mouth, purple eyes, upper body, flower, white hair, multicolored hair, hairband, frills, puffy sleeves, white gloves, hair flower, apron, black dress, from side, looking to the side, maid, maid headdress, rose, white bow, juliet sleeves, white apron, frilled apron, back bow, scissors, frilled hairband, black flower\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru039.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, hair ornament, white background, closed mouth, purple eyes, upper body, braid, flower, white hair, japanese clothes, wings, hair flower, kimono, hair over one eye, from side, looking to the side, black kimono, black flower, kanzashi, chrysanthemum\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru040.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, gloves, long sleeves, white background, dress, closed mouth, purple eyes, upper body, white hair, frills, white gloves, hair over one eye, apron, black dress, maid, maid headdress, black ribbon, waist apron, white apron, adjusting clothes, adjusting gloves\n",
            " 38% 5/13 [00:32<00:51,  6.46s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru041.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, breasts, looking at viewer, bangs, simple background, hair ornament, long sleeves, white background, dress, bow, holding, jewelry, closed mouth, purple eyes, upper body, white hair, short sleeves, hair bow, hairband, earrings, frills, parted lips, one eye closed, hairclip, puffy sleeves, hand up, medium hair, blurry, apron, black dress, puffy short sleeves, maid, maid headdress, black bow, leaning forward, juliet sleeves, white apron, layered sleeves, short over long sleeves, frilled hairband\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru042.jpg:\n",
            "  Character tags: izayoi sakuya\n",
            "  General tags: 1girl, solo, looking at viewer, blush, short hair, bangs, hair ornament, white background, bow, upper body, braid, flower, white hair, hair bow, frills, parted lips, choker, hair flower, scarf, twin braids, from side, grey eyes, maid, maid headdress, green bow, red scarf, black flower\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru043.jpg:\n",
            "  Character tags: rem (re:zero)\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, blue eyes, hair ornament, ribbon, holding, closed mouth, blue hair, hair ribbon, upper body, flower, hairband, frills, hair over one eye, maid, maid headdress, black ribbon, neck ribbon, eyes visible through hair, x hair ornament, black background, portrait, roswaal mansion maid uniform\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru044.jpg:\n",
            "  Character tags: rem (re:zero), ram (re:zero)\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, ribbon, holding, bare shoulders, closed mouth, upper body, pink hair, frills, detached sleeves, pink eyes, hair over one eye, maid, maid headdress, black ribbon, neck ribbon, eyes visible through hair, x hair ornament, black background, ribbon trim, portrait, roswaal mansion maid uniform\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru045.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, hair ornament, closed mouth, blue hair, purple eyes, upper body, pink hair, flower, white hair, multicolored hair, japanese clothes, virtual youtuber, hand up, hair flower, kimono, hair over one eye, from side, floral print, bug, black background, butterfly, portrait, branch, black kimono, black flower\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru046.jpg:\n",
            "  Character tags: remilia scarlet\n",
            "  General tags: 1girl, solo, looking at viewer, blush, smile, short hair, bangs, simple background, red eyes, hat, white background, dress, bow, ribbon, hair between eyes, closed mouth, upper body, flower, frills, one eye closed, wings, red ribbon, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, hat flower, white capelet, white ascot, frilled capelet\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru047.jpg:\n",
            "  Character tags: remilia scarlet\n",
            "  General tags: 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru048.jpg:\n",
            "  Character tags: izayoi sakuya\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, blue eyes, simple background, shirt, hair ornament, white background, hair between eyes, white shirt, braid, flower, ahoge, white hair, frills, parted lips, hair flower, medium hair, scarf, hair over one eye, twin braids, maid headdress, floating hair, rose, eyes visible through hair, white flower, portrait, red scarf, white rose\n",
            " 46% 6/13 [00:33<00:38,  5.55s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru049.jpg:\n",
            "  Character tags: hakurei reimu\n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, brown hair, long sleeves, white background, bow, holding, brown eyes, upper body, hair bow, sidelocks, frills, parted lips, detached sleeves, hand up, wide sleeves, scarf, red bow, ascot, hair tubes, ribbon trim, ribbon-trimmed sleeves, yellow ascot, red vest, frilled bow, yellow scarf\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru050.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, shirt, black hair, hair ornament, long sleeves, ribbon, upper body, flower, parted lips, choker, hair flower, bracelet, grey eyes, black shirt, black ribbon, blue background, black choker, black flower\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru051.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, short hair, bangs, simple background, white background, jewelry, white hair, parted lips, hair over one eye, ascot, looking away, crescent, brooch, portrait, white ascot, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru052.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, short hair, bangs, simple background, hair ornament, white background, hair between eyes, closed mouth, green eyes, flower, white hair, sidelocks, multicolored hair, parted lips, green hair, choker, hair flower, grey background, from side, streaked hair, rose, headphones, black choker, looking away, portrait, headphones around neck, black flower, black rose, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru053.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, open mouth, bangs, simple background, shirt, hair ornament, long sleeves, white background, holding, jacket, yellow eyes, white shirt, upper body, braid, white hair, multicolored hair, hairband, glasses, collared shirt, off shoulder, bag, vest, single braid, pale skin, semi-rimless eyewear, black-framed eyewear, black vest\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru054.jpg:\n",
            "  Character tags: hakurei reimu, kirisame marisa\n",
            "  General tags: long hair, looking at viewer, blush, bangs, multiple girls, blonde hair, simple background, brown hair, shirt, hair ornament, long sleeves, hat, white background, bow, ribbon, holding, 2girls, hair between eyes, bare shoulders, brown eyes, jewelry, closed mouth, hair ribbon, yellow eyes, white shirt, upper body, braid, flower, hair bow, sidelocks, frills, parted lips, detached sleeves, choker, hair flower, medium hair, star (symbol), looking at another, red bow, looking to the side, wrist cuffs, single braid, black headwear, bell, mask, witch hat, rose, black choker, expressionless, hair tubes, light smile, white flower, blue ribbon, crescent, red flower, tassel, instrument, ribbon trim, jingle bell, hat ornament, blue flower, tress ribbon, star hair ornament, mask on head, blue rose, fox mask, frilled bow, playing instrument, holding instrument, violin, embellished costume, bow (music)\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru055.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, blush, bangs, hair ornament, gloves, hair between eyes, jewelry, upper body, pink hair, flower, parted lips, one eye closed, black gloves, pink eyes, ring, black background, single glove\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru056.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, bangs, simple background, brown hair, black hair, hair ornament, white background, purple eyes, flower, sidelocks, parted lips, hair flower, mole, from side, ascot, eyelashes, mole under eye, profile, looking up, portrait, white ascot\n",
            " 54% 7/13 [00:42<00:36,  6.10s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru057.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, simple background, hair ornament, white background, ribbon, hair between eyes, twintails, closed mouth, monochrome, flower, white hair, choker, hair flower, head tilt, grey eyes, black ribbon, neck ribbon, black choker, portrait\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru058.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, short hair, bangs, blue eyes, simple background, hair ornament, white background, animal ears, hair between eyes, jewelry, monochrome, flower, white hair, parted lips, choker, hair flower, animal ear fluff, grey eyes, animal, black choker, looking away, brooch, portrait, fish, goldfish, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru059.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, white background, hair between eyes, jewelry, closed mouth, green eyes, white hair, earrings, horns, choker, grey background, grey eyes, black choker, portrait, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru060.jpg:\n",
            "  Character tags: izayoi sakuya\n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, blue eyes, simple background, hair ornament, white background, hair between eyes, braid, flower, white hair, frills, parted lips, hair flower, medium hair, scarf, hair over one eye, twin braids, grey eyes, maid headdress, floating hair, rose, eyes visible through hair, white flower, letterboxed, portrait, red scarf, white rose\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru061.jpg:\n",
            "  Character tags: cirno\n",
            "  General tags: 1girl, solo, looking at viewer, smile, short hair, bangs, blue eyes, simple background, shirt, white background, dress, bow, ribbon, hair between eyes, closed mouth, blue hair, white shirt, upper body, short sleeves, hair bow, wings, collared shirt, red ribbon, head tilt, neck ribbon, blue bow, ice, chromatic aberration, ice wings\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru062.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, smile, open mouth, bangs, simple background, hair ornament, red eyes, gloves, white background, ribbon, twintails, upper body, flower, :d, frills, teeth, sleeveless, white gloves, hair flower, upper teeth only, own hands together, red flower, interlocked fingers, antlers\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru063.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, open mouth, bangs, blue eyes, simple background, shirt, black hair, gloves, white background, bow, blue hair, white shirt, upper body, sidelocks, multicolored hair, teeth, black gloves, collared shirt, bowtie, hair bun, streaked hair, grey eyes, double bun, black bow, bird, own hands together, sharp teeth, interlocked fingers, fish, half gloves, hair horns\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru064.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, skirt, simple background, shirt, long sleeves, white background, holding, closed mouth, standing, full body, white shirt, ahoge, white hair, pantyhose, pleated skirt, boots, puffy sleeves, black skirt, cape, black footwear, grey eyes, black pantyhose, black ribbon, capelet, animal, puffy long sleeves, branch, black cape, bucket, black capelet, watering can, deer, holding bucket\n",
            " 62% 8/13 [00:43<00:27,  5.49s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru065.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, white background, jewelry, white hair, parted lips, star (symbol), hair over one eye, ascot, crescent, brooch, portrait, white ascot\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru066.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, short hair, bangs, simple background, white background, bare shoulders, upper body, grey hair, hairband, parted lips, choker, off shoulder, collar, from side, grey eyes, profile, black choker, looking away, looking up, crescent, portrait, black collar\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru067.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, shirt, hair ornament, gloves, ribbon, holding, white shirt, upper body, flower, white hair, parted lips, wings, hairclip, white gloves, hair flower, hair over one eye, black ribbon, neck ribbon, halo, eyes visible through hair, black background, feathered wings, black wings, angel wings, camera, mini wings, black flower, holding camera\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru068.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru069.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, shirt, hair ornament, gloves, white background, ribbon, white shirt, upper body, flower, white hair, short sleeves, hairband, frills, parted lips, black gloves, hand up, hair flower, grey eyes, hands up, black ribbon, neck ribbon, capelet, rose, bug, black hairband, hand on own chest, butterfly, black capelet, black flower, black rose\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru070.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, gloves, long sleeves, white background, dress, closed mouth, purple eyes, flower, white hair, hairband, frills, puffy sleeves, white gloves, hand up, hair flower, scarf, apron, black dress, head tilt, maid, maid headdress, juliet sleeves, white apron, maid apron, white scarf, black flower\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru071.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, blush, short hair, bangs, simple background, hair ornament, white background, jewelry, upper body, flower, white hair, parted lips, choker, hair flower, collar, ascot, rose, looking away, eyes visible through hair, brooch, portrait, white ascot, black flower, black rose\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru072.jpg:\n",
            "  Character tags: kaenbyou rin\n",
            "  General tags: 1girl, solo, looking at viewer, smile, bangs, simple background, white background, bow, ribbon, animal ears, closed mouth, tail, monochrome, braid, white hair, hair bow, choker, cat ears, hand up, blunt bangs, twin braids, cat tail, profile, black choker, light smile, multiple tails, portrait, extra ears, tail ornament, two tails\n",
            " 69% 9/13 [00:51<00:22,  5.67s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru073.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, bangs, brown hair, hat, hair between eyes, yellow eyes, upper body, parted lips, looking away, letterboxed, portrait, rope, rain, looking ahead\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru074.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, bangs, simple background, black hair, hair ornament, white background, jewelry, purple eyes, parted lips, mole, from side, ascot, eyelashes, mole under eye, looking up, portrait, on head, white ascot\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru075.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, white background, hair between eyes, jewelry, green eyes, upper body, grey hair, parted lips, horns, choker, black choker, ring, portrait, hand on own shoulder\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru076.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, blush, short hair, bangs, simple background, white background, bow, hair between eyes, monochrome, white hair, hair bow, greyscale, parted lips, choker, grey background, hair bun, single hair bun, portrait\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru077.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, blush, short hair, bangs, simple background, shirt, hair ornament, white background, closed mouth, flower, white hair, collared shirt, hair flower, grey background, from side, profile, rose, portrait, black flower\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru078.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, skirt, simple background, hair ornament, long sleeves, white background, holding, hair between eyes, closed mouth, standing, jacket, monochrome, full body, white hair, pantyhose, pleated skirt, boots, bag, hair bun, black footwear, grey eyes, capelet, single hair bun, walking, poncho\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru079.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, blush, bangs, simple background, white background, hair between eyes, twintails, closed mouth, green eyes, monochrome, flower, white hair, greyscale, choker, ascot, eyelashes, portrait\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru080.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, shirt, black hair, jewelry, closed mouth, green eyes, choker, collared shirt, mole, eyelashes, mole under eye, black choker, portrait\n",
            " 77% 10/13 [00:52<00:15,  5.21s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru081.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, shirt, hair ornament, white background, bow, ribbon, green eyes, white shirt, upper body, flower, parted lips, glasses, collared shirt, hair flower, neck ribbon, portrait, round eyewear, green ribbon, black flower, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru082.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, white background, hair between eyes, closed mouth, white hair, choker, pink eyes, black choker, portrait, close-up\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru083.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, open mouth, bangs, ribbon, braid, white hair, parted lips, horns, tears, from side, grey eyes, profile, looking away, crying, black background, portrait, light particles, crying with eyes open, looking ahead\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru084.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, smile, short hair, bangs, blonde hair, hair ornament, animal ears, flower, parted lips, food, hair flower, from side, grey eyes, fruit, animal, leaf, black background, portrait, yellow flower, mouse ears, mouse, orange (fruit), orange slice\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru085.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, white background, ribbon, hair between eyes, white hair, parted lips, horns, choker, grey background, grey eyes, maid headdress, black choker, portrait, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru086.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, bangs, hair ornament, long sleeves, holding, jewelry, upper body, earrings, parted lips, choker, pink eyes, hair over one eye, staff\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru087.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, bangs, simple background, shirt, hair ornament, white background, ribbon, hair between eyes, closed mouth, white shirt, white hair, collared shirt, pink eyes, maid headdress, neck ribbon, portrait, snake, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru088.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, short hair, bangs, simple background, hair ornament, jewelry, closed mouth, green eyes, white hair, from side, aqua eyes, eyelashes, profile, crown, crescent, black background, portrait, looking ahead, cropped shoulders\n",
            " 85% 11/13 [00:58<00:10,  5.29s/it]\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru089.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, blush, open mouth, bangs, hair ornament, hair between eyes, pink hair, teeth, pink eyes, nail polish, upper teeth only, black background, portrait, pink nails, hands on own face, hands on own cheeks\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru090.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, simple background, hair ornament, hair between eyes, closed mouth, white hair, choker, pointy ears, black choker, expressionless, portrait, yellow background, fish\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru091.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, blue eyes, simple background, gloves, holding, hair between eyes, jewelry, weapon, white hair, earrings, parted lips, choker, black gloves, sword, fingerless gloves, holding weapon, armor, black choker, holding sword, portrait, yellow background\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru092.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, bangs, blonde hair, simple background, closed mouth, green eyes, frills, expressionless, black background, portrait, snail, cropped shoulders\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru093.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, short hair, open mouth, bangs, hair ornament, hair between eyes, pink hair, flower, japanese clothes, horns, fang, hair flower, pink eyes, from side, petals, letterboxed, portrait, skin fang\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru094.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, blue eyes, hair ornament, gloves, holding, hair between eyes, jewelry, upper body, weapon, flower, white hair, parted lips, black gloves, sword, hair flower, hood, holding weapon, hair over one eye, bracelet, aqua eyes, holding sword, feathers\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru095.jpg:\n",
            "  Character tags: kaenbyou rin\n",
            "  General tags: 1girl, solo, long hair, breasts, looking at viewer, bangs, red eyes, white background, dress, bow, animal ears, bare shoulders, tail, upper body, braid, hair bow, red hair, frills, choker, looking back, cat ears, off shoulder, from behind, black dress, twin braids, cat tail, animal ear fluff, black bow, profile, black choker, bug, multiple tails, butterfly, extra ears, off-shoulder dress, sideways glance, two tails\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru096.jpg:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, breasts, looking at viewer, short hair, bangs, blue eyes, simple background, white background, animal ears, hair between eyes, collarbone, upper body, flower, white hair, small breasts, parted lips, choker, cat ears, animal ear fluff, black choker\n",
            "100% 13/13 [00:59<00:00,  4.60s/it]\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru097.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, looking at viewer, bangs, blonde hair, gloves, hair between eyes, closed mouth, yellow eyes, white hair, horns, black gloves, looking to the side, portrait\n",
            "\n",
            "/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data/hito_komoru098.png:\n",
            "  Character tags: \n",
            "  General tags: 1girl, solo, long hair, looking at viewer, bangs, hair ornament, hair between eyes, closed mouth, flower, white hair, hair flower, grey eyes, white flower, portrait\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "#@title ### 3.2.2. Waifu Diffusion 1.4 Tagger V2\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "#@markdown [Waifu Diffusion 1.4 Tagger V2](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) is a Danbooru-styled image classification model developed by SmilingWolf. It can also be useful for general image tagging, for example, `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background`.\n",
        "model = \"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\" #@param [\"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\", \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\", \"SmilingWolf/wd-v1-4-convnext-tagger-v2\", \"SmilingWolf/wd-v1-4-vit-tagger-v2\"]\n",
        "#@markdown Separate `undesired_tags` with comma `(,)` if you want to remove multiple tags, e.g. `1girl,solo,smile`.\n",
        "undesired_tags = \"\" #@param {type:'string'}\n",
        "#@markdown Adjust `general_threshold` for pruning tags (less tags, less flexible). `character_threshold` is useful if you want to train with character tags, e.g. `hakurei reimu`.\n",
        "general_threshold = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "character_threshold = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"           : train_data_dir,\n",
        "    \"batch_size\"                : 8,\n",
        "    \"repo_id\"                   : model,\n",
        "    \"recursive\"                 : True,\n",
        "    \"remove_underscore\"         : True,\n",
        "    \"general_threshold\"         : general_threshold,\n",
        "    \"character_threshold\"       : character_threshold,\n",
        "    \"caption_extension\"         : \".txt\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"debug\"                     : True,\n",
        "    \"undesired_tags\"            : undesired_tags\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python tag_images_by_wd14_tagger.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_mLVURhM9PFE"
      },
      "outputs": [],
      "source": [
        "# @title ### 3.2.3. Custom Caption/Tag\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Add or remove custom tags here.\n",
        "extension   = \".txt\"  # @param [\".txt\", \".caption\"]\n",
        "custom_tag  = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Use `sub_folder` option to specify a subfolder for multi-concept training. \n",
        "# @markdown > Specify `--all` to process all subfolders/`recursive`\n",
        "sub_folder  = \"\" #@param {type: \"string\"}\n",
        "# @markdown Enable this to append custom tags at the end of lines.\n",
        "append      = False  # @param {type:\"boolean\"}\n",
        "# @markdown Enable this if you want to remove captions/tags instead.\n",
        "remove_tag  = False  # @param {type:\"boolean\"}\n",
        "recursive   = False\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder == \"--all\":\n",
        "    image_dir = train_data_dir\n",
        "    recursive = True\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def process_tags(filename, custom_tag, append, remove_tag):\n",
        "    contents = read_file(filename)\n",
        "    tags = [tag.strip() for tag in contents.split(',')]\n",
        "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
        "\n",
        "    for custom_tag in custom_tags:\n",
        "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
        "        if remove_tag:\n",
        "            while custom_tag in tags:\n",
        "                tags.remove(custom_tag)\n",
        "        else:\n",
        "            if custom_tag not in tags:\n",
        "                if append:\n",
        "                    tags.append(custom_tag)\n",
        "                else:\n",
        "                    tags.insert(0, custom_tag)\n",
        "\n",
        "    contents = ', '.join(tags)\n",
        "    write_file(filename, contents)\n",
        "\n",
        "def process_directory(image_dir, tag, append, remove_tag, recursive):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        \n",
        "        if os.path.isdir(file_path) and recursive:\n",
        "            process_directory(file_path, tag, append, remove_tag, recursive)\n",
        "        elif filename.endswith(extension):\n",
        "            process_tags(file_path, tag, append, remove_tag)\n",
        "\n",
        "tag = custom_tag\n",
        "\n",
        "if not any(\n",
        "    [filename.endswith(extension) for filename in os.listdir(image_dir)]\n",
        "):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")):\n",
        "            open(\n",
        "                os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
        "                \"w\",\n",
        "            ).close()\n",
        "\n",
        "if custom_tag:\n",
        "    process_directory(image_dir, tag, append, remove_tag, recursive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHNbl3O_NSS0"
      },
      "source": [
        "# IV. Training \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "# @title ## **4.1. LoRa: Low-Rank Adaptation Config**\n",
        "# @markdown Kohya's `LoRA` renamed to `LoRA-LierLa` and Kohya's `LoCon` renamed to `LoRA-C3Lier`, read [official announcement](https://github.com/kohya-ss/sd-scripts/blob/849bc24d205a35fbe1b2a4063edd7172533c1c01/README.md#naming-of-lora).\n",
        "network_category = \"LoRA_C3Lier\"  # @param [\"LoRA_LierLa\", \"LoRA_C3Lier\", \"DyLoRA_LierLa\", \"DyLoRA_C3Lier\", \"LoCon\", \"LoHa\", \"IA3\", \"LoKR\", \"DyLoRA_Lycoris\"]\n",
        "\n",
        "# @markdown | network_category | network_dim | network_alpha | conv_dim | conv_alpha | unit |\n",
        "# @markdown | :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "# @markdown | LoRA-LierLa | 32 | 1 | - | - | - |\n",
        "# @markdown | LoCon/LoRA-C3Lier | 16 | 8 | 8 | 1 | - |\n",
        "# @markdown | LoHa | 8 | 4 | 4 | 1 | - |\n",
        "# @markdown | Other Category | ? | ? | ? | ? | - |\n",
        "\n",
        "# @markdown Specify `network_args` to add `optional` training args, like for specifying each 25 block weight, read [this](https://github.com/kohya-ss/sd-scripts/blob/main/train_network_README-ja.md#%E9%9A%8E%E5%B1%A4%E5%88%A5%E5%AD%A6%E7%BF%92%E7%8E%87)\n",
        "network_args    = \"\"  # @param {'type':'string'}\n",
        "\n",
        "# @markdown Specify `network_weight` for resuming training. Make sure all hyperparameters are the same as the last training, or it will raise an error.\n",
        "network_weight  = \"\"  # @param {'type':'string'}\n",
        "\n",
        "# @markdown ### **Linear Layer Config**\n",
        "# @markdown Used by all `network_category`. When in doubt, set `network_dim = network_alpha`\n",
        "network_dim     = 64  # @param {'type':'number'}\n",
        "network_alpha   = 64  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **Convolutional Layer Config**\n",
        "# @markdown Only required if `network_category` is not `LoRA_LierLa`, as it involves training convolutional layers in addition to linear layers.\n",
        "conv_dim        = 64  # @param {'type':'number'}\n",
        "conv_alpha      = 64  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **DyLoRA Config**\n",
        "# @markdown Only required if `network_category` is `DyLoRA_LierLa` and `DyLoRA_C3Lier`\n",
        "unit = 4  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(network_args, str):\n",
        "    network_args = network_args.strip()\n",
        "    if network_args.startswith('[') and network_args.endswith(']'):\n",
        "        try:\n",
        "            network_args = ast.literal_eval(network_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing network_args: {e}\\n\")\n",
        "            network_args = []\n",
        "    elif len(network_args) > 0:\n",
        "        print(f\"WARNING! '{network_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        network_args = []\n",
        "    else:\n",
        "        network_args = []\n",
        "else:\n",
        "    network_args = []\n",
        "    \n",
        "network_config = {\n",
        "    \"LoRA_LierLa\": {\n",
        "        \"module\": \"networks.lora\", \n",
        "        \"args\"  : []\n",
        "    },\n",
        "    \"LoRA_C3Lier\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\", \n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_LierLa\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_C3Lier\": {\n",
        "        \"module\": \"networks.dylora\", \n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\", \n",
        "            f\"conv_alpha={conv_alpha}\", \n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoCon\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=locon\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoHa\": {\n",
        "        \"module\": \"lycoris.kohya\", \n",
        "        \"args\"  : [\n",
        "            f\"algo=loha\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"IA3\": {\n",
        "        \"module\": \"lycoris.kohya\", \n",
        "        \"args\"  : [\n",
        "            f\"algo=ia3\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoKR\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=lokr\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_Lycoris\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=dylora\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "network_module = network_config[network_category][\"module\"]\n",
        "network_args.extend(network_config[network_category][\"args\"])\n",
        "\n",
        "print(f\"Selected configuration:\")\n",
        "if network_weight:\n",
        "    print(f\"\\t- Resuming training from: {network_weight}\")\n",
        "print(f\"\\t- Network category: {network_category}\")\n",
        "print(f\"\\t- Network module: {network_module}\")\n",
        "print(f\"\\t- Linear dim: {network_dim}\")\n",
        "print(f\"\\t- Linear alpha: {network_alpha}\")\n",
        "print(f\"\\t- Network arguments: {network_args}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cJgLfRtlHSjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfb5687-7377-45b7-dc1a-7a857bd19ab0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected configuration:\n",
            "\t- Network category: LoRA_C3Lier\n",
            "\t- Network module: networks.lora\n",
            "\t- Linear dim: 64\n",
            "\t- Linear alpha: 64\n",
            "\t- Network arguments: ['conv_dim=64', 'conv_alpha=64']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **4.2. Optimizer Config**\n",
        "# @markdown Set to `AdamW8bit` for a good start.\n",
        "optimizer_type = \"AdamW8bit\"  # @param [\"AdamW\", \"AdamW8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation\", \"AdaFactor\"]\n",
        "\n",
        "# @markdown Specify `optimizer_args` to add `additional` args for optimizer, e.g: `[\"decouple=True\",\"weight_decay=0.6\"]` for `DAdaptation`\n",
        "optimizer_args = \"\\\"weight_decay=0.6\\\"\"  # @param {'type':'string'}\n",
        "\n",
        "# @markdown ### **Learning Rate Config**\n",
        "# @markdown Different `optimizer_type` and `network_category` for some condition requires different learning rate. It's recommended to set `text_encoder_lr = 1/2 * unet_lr`\n",
        "unet_lr = 1e-4  # @param {'type':'number'}\n",
        "# @markdown Try to set `train_text_encoder` to `False` if you're not train on object.\n",
        "train_text_encoder = True  # @param {'type':'boolean'}\n",
        "text_encoder_lr = 5e-5  # @param {'type':'number'\n",
        "\n",
        "# @markdown ### **LR Scheduler Config**\n",
        "# @markdown `lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs.\n",
        "lr_scheduler = \"cosine\"  # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"] {allow-input: false}\n",
        "lr_warmup_steps = 0  # @param {'type':'number'}\n",
        "\n",
        "# @markdown Specify `lr_scheduler_num` with `num_cycles` value for `cosine_with_restarts` or `power` value for `polynomial`\n",
        "lr_scheduler_num = 0  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(optimizer_args, str):\n",
        "    optimizer_args = optimizer_args.strip()\n",
        "    if optimizer_args.startswith('[') and optimizer_args.endswith(']'):\n",
        "        try:\n",
        "            optimizer_args = ast.literal_eval(optimizer_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing optimizer_args: {e}\\n\")\n",
        "            optimizer_args = []\n",
        "    elif len(optimizer_args) > 0:\n",
        "        print(f\"WARNING! '{optimizer_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        optimizer_args = []\n",
        "    else:\n",
        "        optimizer_args = []\n",
        "else:\n",
        "    optimizer_args = []\n",
        "    \n",
        "print(f\"Selected configuration:\")\n",
        "print(f\"\\t- Using {optimizer_type} as Optimizer\")\n",
        "print(f\"\\t- Optimizer arguments: {optimizer_args}\")\n",
        "print(f\"\\t- UNet learning rate: {unet_lr}\")\n",
        "if train_text_encoder:\n",
        "    print(\"\\t- Train Text Encoder\")\n",
        "    print(f\"\\t- Text encoder learning rate: {text_encoder_lr}\")\n",
        "print(f\"\\t- Learning rate warmup steps: {lr_warmup_steps}\")\n",
        "print(f\"\\t- Learning rate Scheduler: {lr_scheduler}\")\n",
        "if lr_scheduler == \"cosine_with_restarts\":\n",
        "    print(f\"\\t- lr_scheduler_num_cycles: {lr_scheduler_num}\")\n",
        "if lr_scheduler == \"polynomial\":\n",
        "    print(f\"\\t- lr_scheduler_power: {lr_scheduler_num}\")\n"
      ],
      "metadata": {
        "id": "JNlw3u8arwir",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64acc42b-ee52-4c12-cea0-da553bc3d5d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING! '\"weight_decay=0.6\"' is not a valid list! Put args like this: [\"args=1\", \"args=2\"]\n",
            "\n",
            "Selected configuration:\n",
            "\t- Using AdamW8bit as Optimizer\n",
            "\t- Optimizer arguments: []\n",
            "\t- UNet learning rate: 0.0001\n",
            "\t- Train Text Encoder\n",
            "\t- Text encoder learning rate: 5e-05\n",
            "\t- Learning rate warmup steps: 0\n",
            "\t- Learning rate Scheduler: cosine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "cellView": "form",
        "id": "-Z4w3lfFKLjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5573f2e3-231a-4eb4-e013-6aca71464c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[datasets]]\n",
            "resolution = 768\n",
            "min_bucket_reso = 320\n",
            "max_bucket_reso = 1280\n",
            "flip_aug = false\n",
            "[[datasets.subsets]]\n",
            "image_dir = \"/content/LoRA/train_data\"\n",
            "num_repeats = 10\n",
            "\n",
            "[[datasets.subsets]]\n",
            "image_dir = \"/content/LoRA/train_data/content\"\n",
            "num_repeats = 10\n",
            "\n",
            "[[datasets.subsets]]\n",
            "image_dir = \"/content/LoRA/train_data/content/training_dir\"\n",
            "num_repeats = 10\n",
            "\n",
            "[[datasets.subsets]]\n",
            "image_dir = \"/content/LoRA/train_data/content/training_dir/hitokomoru_dataset\"\n",
            "num_repeats = 10\n",
            "\n",
            "[[datasets.subsets]]\n",
            "image_dir = \"/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data\"\n",
            "num_repeats = 10\n",
            "\n",
            "[[datasets.subsets]]\n",
            "image_dir = \"/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data\"\n",
            "num_repeats = 10\n",
            "\n",
            "\n",
            "[general]\n",
            "enable_bucket = true\n",
            "caption_extension = \".txt\"\n",
            "shuffle_caption = true\n",
            "keep_tokens = 0\n",
            "\n",
            "[prompt]\n",
            "negative_prompt = \"(worst quality, low quality:1.4)\"\n",
            "width = 512\n",
            "height = 768\n",
            "scale = 7\n",
            "sample_steps = 28\n",
            "[[prompt.subset]]\n",
            "prompt = \"masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\"\n",
            "\n",
            "[[prompt.subset]]\n",
            "prompt = \"masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\"\n",
            "\n",
            "\n",
            "[model_arguments]\n",
            "v2 = true\n",
            "v_parameterization = true\n",
            "pretrained_model_name_or_path = \"/content/pretrained_model/wd-beta3-base-fp16.safetensors\"\n",
            "vae = \"/content/vae/animevae.pt\"\n",
            "\n",
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "unet_lr = 0.0001\n",
            "text_encoder_lr = 5e-5\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 64\n",
            "network_alpha = 64\n",
            "network_args = [ \"conv_dim=64\", \"conv_alpha=64\",]\n",
            "network_train_unet_only = false\n",
            "network_train_text_encoder_only = false\n",
            "\n",
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdamW8bit\"\n",
            "learning_rate = 0.0001\n",
            "max_grad_norm = 1.0\n",
            "optimizer_args = []\n",
            "lr_scheduler = \"cosine\"\n",
            "lr_warmup_steps = 0\n",
            "\n",
            "[dataset_arguments]\n",
            "cache_latents = true\n",
            "cache_latents_to_disk = true\n",
            "debug_dataset = false\n",
            "vae_batch_size = 4\n",
            "\n",
            "[training_arguments]\n",
            "output_dir = \"/content/LoRA/output\"\n",
            "output_name = \"hitokomoru_locon_wd_beta3\"\n",
            "save_precision = \"fp16\"\n",
            "save_every_n_epochs = 1\n",
            "train_batch_size = 2\n",
            "max_token_length = 225\n",
            "mem_eff_attn = false\n",
            "xformers = true\n",
            "max_train_epochs = 10\n",
            "max_data_loader_n_workers = 8\n",
            "persistent_data_loader_workers = true\n",
            "gradient_accumulation_steps = 1\n",
            "mixed_precision = \"fp16\"\n",
            "lowram = true\n",
            "\n",
            "[logging_arguments]\n",
            "log_with = \"wandb\"\n",
            "log_tracker_name = \"hitokomoru_locon_wd_beta3\"\n",
            "logging_dir = \"/content/LoRA/logs\"\n",
            "\n",
            "[sample_prompt_arguments]\n",
            "sample_every_n_epochs = 1\n",
            "sample_sampler = \"k_dpm_2_a\"\n",
            "\n",
            "[dreambooth_arguments]\n",
            "prior_loss_weight = 1.0\n",
            "\n",
            "[saving_arguments]\n",
            "save_model_as = \"safetensors\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **4.3. Training Config**\n",
        "\n",
        "import toml\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown ### **Project Config**\n",
        "base_model          = \"Stable Diffusion 2.x 768\" #@param [\"Stable Diffusion 1.x\", \"Stable Diffusion 2.x\", \"Stable Diffusion 2.x 768\"]\n",
        "project_name        = \"hitokomoru_locon_wd_beta3\"  # @param {type:\"string\"}\n",
        "# @markdown Get your `wandb_api_key` [here](https://wandb.ai/settings) to logs with wandb.\n",
        "wandb_api_key       = \"eaa332c113ae3d9faa34d42a2d37502b8cd00371\" # @param {type:\"string\"}\n",
        "# @markdown ### **Dataset Config**\n",
        "num_repeats         = 10  # @param {type:\"number\"}\n",
        "# @markdown Please refer to `3.2.3. Custom Caption/Tag (Optional)` if you want to append `activation_word` to captions/tags\n",
        "resolution          = 768  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "flip_aug            = False  # @param {type:\"boolean\"}\n",
        "caption_extension   = \".txt\"  # @param [\"none\", \".txt\", \".caption\"]\n",
        "keep_tokens         = 0  # @param {type:\"number\"}\n",
        "# @markdown ### **General Config**\n",
        "num_epochs          = 10  # @param {type:\"number\"}\n",
        "train_batch_size    = 2  # @param {type:\"number\"}\n",
        "mixed_precision     = \"fp16\"  # @param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "clip_skip           = 2  # @param {type:\"number\"}\n",
        "seed                = -1  # @param {type:\"number\"}\n",
        "# @markdown ### **Save Output Config**\n",
        "save_precision      = \"fp16\"  # @param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs = 1  # @param {type:\"number\"}\n",
        "# @markdown ### **Sample Prompt Config**\n",
        "quality_prompt      = \"masterpiece, best quality, \"\n",
        "custom_prompt       = \"\" # @param {type:\"string\"}\n",
        "enable_sample     = True  # @param {type:\"boolean\"}\n",
        "num_prompt          = 2  # @param {type:\"number\"}\n",
        "# @markdown ### **Advanced Training Config**\n",
        "# @markdown Gamma for reducing the weight of high-loss timesteps. Lower numbers have a stronger effect. The paper recommends `5`. Read the paper [here](https://arxiv.org/abs/2303.09556).\n",
        "min_snr_gamma       = -1 #@param {type:\"number\"}\n",
        "# @markdown Control and easily generating darker or light images by offset the noise when fine-tuning the model. Recommended value: `0.1`. Read [Diffusion With Offset Noise](https://www.crosslabs.org//blog/diffusion-with-offset-noise)\n",
        "noise_offset        = -1  # @param {type:\"number\"}\n",
        "\n",
        "logging_dir         = \"/content/LoRA/logs\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "prompt_config = {\n",
        "    \"prompt\": {\n",
        "        \"negative_prompt\" : \"(worst quality, low quality:1.4)\",\n",
        "        \"width\"           : 512,\n",
        "        \"height\"          : 768,\n",
        "        \"scale\"           : 7,\n",
        "        \"sample_steps\"    : 28,\n",
        "        \"subset\"          : [],\n",
        "    }\n",
        "}\n",
        "\n",
        "train_config = {\n",
        "    \"model_arguments\": {\n",
        "        \"v2\"                            : True if base_model in [\"Stable Diffusion 2.x\", \"Stable Diffusion 2.x 768\"] else False,\n",
        "        \"v_parameterization\"            : True if base_model == \"Stable Diffusion 2.x 768\" else False,\n",
        "        \"pretrained_model_name_or_path\" : model_path,\n",
        "        \"vae\"                           : vae_path,\n",
        "    },\n",
        "    \"additional_network_arguments\": {\n",
        "        \"no_metadata\"                     : False,\n",
        "        \"unet_lr\"                         : float(unet_lr) if not optimizer_type == \"DAdaptation\" else None,\n",
        "        \"text_encoder_lr\"                 : float(text_encoder_lr) if train_text_encoder and not optimizer_type == \"DAdaptation\" else None,\n",
        "        \"network_weights\"                 : network_weight,\n",
        "        \"network_module\"                  : network_module,\n",
        "        \"network_dim\"                     : network_dim,\n",
        "        \"network_alpha\"                   : network_alpha,\n",
        "        \"network_args\"                    : network_args,\n",
        "        \"network_train_unet_only\"         : True if not train_text_encoder else False,\n",
        "        \"network_train_text_encoder_only\" : False,\n",
        "        \"training_comment\"                : None,\n",
        "    },\n",
        "    \"optimizer_arguments\": {\n",
        "        \"min_snr_gamma\"           : min_snr_gamma if not min_snr_gamma == -1 else None,\n",
        "        \"optimizer_type\"          : optimizer_type,\n",
        "        \"learning_rate\"           : unet_lr,\n",
        "        \"max_grad_norm\"           : 1.0,\n",
        "        \"optimizer_args\"          : optimizer_args,\n",
        "        \"lr_scheduler\"            : lr_scheduler,\n",
        "        \"lr_warmup_steps\"         : lr_warmup_steps,\n",
        "        \"lr_scheduler_num_cycles\" : lr_scheduler_num if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\"      : lr_scheduler_num if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_scheduler_type\"       : None,\n",
        "        \"lr_scheduler_args\"       : None,\n",
        "    },\n",
        "    \"dataset_arguments\": {\n",
        "        \"cache_latents\"         : True,\n",
        "        \"cache_latents_to_disk\" : True,\n",
        "        \"debug_dataset\"         : False,\n",
        "        \"vae_batch_size\"        : 4,\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"output_dir\"                    : output_dir,\n",
        "        \"output_name\"                   : project_name if project_name else \"last\",\n",
        "        \"save_precision\"                : save_precision,\n",
        "        \"save_every_n_epochs\"           : save_every_n_epochs,\n",
        "        \"save_n_epoch_ratio\"            : None,\n",
        "        \"save_last_n_epochs\"            : None,\n",
        "        \"save_state\"                    : None,\n",
        "        \"save_last_n_epochs_state\"      : None,\n",
        "        \"resume\"                        : None,\n",
        "        \"train_batch_size\"              : train_batch_size,\n",
        "        \"max_token_length\"              : 225,\n",
        "        \"mem_eff_attn\"                  : False,\n",
        "        \"xformers\"                      : True,\n",
        "        \"max_train_epochs\"              : num_epochs,\n",
        "        \"max_data_loader_n_workers\"     : 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"seed\"                          : seed if seed > 0 else None,\n",
        "        \"gradient_checkpointing\"        : None,\n",
        "        \"gradient_accumulation_steps\"   : 1,\n",
        "        \"mixed_precision\"               : mixed_precision,\n",
        "        \"clip_skip\"                     : clip_skip if base_model == \"Stable Diffusion 1.x\" else None,\n",
        "        \"noise_offset\"                  : noise_offset if noise_offset > 0 else None,\n",
        "        \"lowram\"                        : True if 'T4' in getoutput('nvidia-smi') else False,\n",
        "    },\n",
        "    \"logging_arguments\": {\n",
        "        \"log_with\"          : \"wandb\" if wandb_api_key else \"tensorboard\",\n",
        "        \"log_tracker_name\"  : project_name if wandb_api_key and not project_name == \"last\" else None,\n",
        "        \"logging_dir\"       : logging_dir,\n",
        "        \"log_prefix\"        : project_name if not wandb_api_key else None,\n",
        "    },\n",
        "    \"sample_prompt_arguments\": {\n",
        "        \"sample_every_n_steps\"    : None,\n",
        "        \"sample_every_n_epochs\"   : save_every_n_epochs if enable_sample else None,\n",
        "        \"sample_sampler\"          : \"k_dpm_2_a\",\n",
        "    },\n",
        "    \"dreambooth_arguments\": {\n",
        "        \"prior_loss_weight\": 1.0,\n",
        "    },\n",
        "    \"saving_arguments\": {\n",
        "        \"save_model_as\": \"safetensors\"\n",
        "    },\n",
        "}\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt):\n",
        "    if enable_sample:\n",
        "        search_pattern = os.path.join(train_data_dir, '**/*' + caption_extension)\n",
        "        caption_files = glob.glob(search_pattern, recursive=True)\n",
        "\n",
        "        if not caption_files:\n",
        "            if not custom_prompt:\n",
        "                custom_prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\"\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = [\n",
        "                {\"prompt\": quality_prompt + custom_prompt if quality_prompt else custom_prompt}\n",
        "            ]\n",
        "        else:\n",
        "            selected_files = random.sample(caption_files, min(num_prompt, len(caption_files)))\n",
        "\n",
        "            prompts = []\n",
        "            for file in selected_files:\n",
        "                with open(file, 'r') as f:\n",
        "                    prompts.append(f.read().strip())\n",
        "\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = []\n",
        "\n",
        "            for prompt in prompts:\n",
        "                new_prompt = {\n",
        "                    \"prompt\": quality_prompt + prompt if quality_prompt else prompt,\n",
        "                }\n",
        "                new_prompt_config['prompt']['subset'].append(new_prompt)\n",
        "\n",
        "        return new_prompt_config\n",
        "    else:\n",
        "        return prompt_config\n",
        " \n",
        "\n",
        "def parse_folder_name(folder_name, num_repeats):\n",
        "    folder_name_parts = folder_name.split(\"_\")\n",
        "\n",
        "    if len(folder_name_parts) == 2:\n",
        "        if folder_name_parts[0].isdigit():\n",
        "            num_repeats = int(folder_name_parts[0])\n",
        "            class_token = folder_name_parts[1].replace(\"_\", \" \")\n",
        "        else:\n",
        "            num_repeats = num_repeats\n",
        "            class_token = None\n",
        "    else:\n",
        "        num_repeats = num_repeats\n",
        "        class_token = None\n",
        "\n",
        "    return num_repeats, class_token\n",
        "\n",
        "def find_image_files(path):\n",
        "    supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "    return [file for file in glob.glob(path + '/**/*', recursive=True) if file.lower().endswith(supported_extensions)]\n",
        "\n",
        "def process_data_dir(data_dir, default_num_repeats, is_reg=False):\n",
        "    if not data_dir or not os.path.isdir(data_dir):\n",
        "        return []\n",
        "\n",
        "    subsets = []\n",
        "\n",
        "    images = find_image_files(data_dir)\n",
        "    if images:\n",
        "        _, class_tokens = parse_folder_name(data_dir, default_num_repeats)\n",
        "\n",
        "        subsets.append({\n",
        "            \"image_dir\": data_dir,\n",
        "            \"num_repeats\": default_num_repeats,\n",
        "            **({\"class_tokens\": is_reg} if class_tokens is not None else {}),\n",
        "            **({\"is_reg\": is_reg} if is_reg else {}),\n",
        "        })\n",
        "\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for folder in dirs:\n",
        "            folder_path = os.path.join(root, folder)\n",
        "            images = find_image_files(folder_path)\n",
        "\n",
        "            if images:\n",
        "                num_repeats, class_tokens = parse_folder_name(folder, default_num_repeats)\n",
        "\n",
        "                subset = {\n",
        "                    \"image_dir\": folder_path,\n",
        "                    \"num_repeats\": num_repeats,\n",
        "                    **({\"class_tokens\": is_reg} if class_tokens is not None else {}),\n",
        "                    **({\"is_reg\": is_reg} if is_reg else {}),\n",
        "                }\n",
        "\n",
        "                if is_reg:\n",
        "                    subset[\"is_reg\"] = True\n",
        "\n",
        "                subsets.append(subset)\n",
        "\n",
        "    return subsets\n",
        "\n",
        "def eliminate_none_variable(config):\n",
        "    for key in config:\n",
        "        if isinstance(config[key], dict):\n",
        "            for sub_key in config[key]:\n",
        "                if config[key][sub_key] == \"\":\n",
        "                    config[key][sub_key] = None\n",
        "        elif config[key] == \"\":\n",
        "            config[key] = None\n",
        "    \n",
        "    return config\n",
        "\n",
        "train_subsets = process_data_dir(train_data_dir, num_repeats)\n",
        "reg_subsets   = process_data_dir(reg_data_dir, num_repeats, is_reg=True)\n",
        "data_subsets  = train_subsets + reg_subsets\n",
        "\n",
        "dataset_config = {\n",
        "    \"general\": {\n",
        "        \"enable_bucket\"     : True,\n",
        "        \"caption_extension\" : caption_extension,\n",
        "        \"shuffle_caption\"   : True,\n",
        "        \"keep_tokens\"       : keep_tokens,\n",
        "    },\n",
        "    \"datasets\": [\n",
        "        {\n",
        "            \"resolution\"      : resolution,\n",
        "            \"min_bucket_reso\" : 320 if resolution > 640 else 256,\n",
        "            \"max_bucket_reso\" : 1280 if resolution > 640 else 1024,\n",
        "            \"flip_aug\"        : flip_aug,\n",
        "            \"subsets\"         : data_subsets,\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "\n",
        "prompt_config = prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt)\n",
        "\n",
        "config_path         = os.path.join(config_dir, \"config_file.toml\")\n",
        "prompt_path         = os.path.join(config_dir, \"sample_prompt.toml\")\n",
        "dataset_config_path = os.path.join(config_dir, \"dataset_config.toml\")\n",
        "\n",
        "config_str          = toml.dumps(eliminate_none_variable(train_config))\n",
        "prompt_str          = toml.dumps(eliminate_none_variable(prompt_config))\n",
        "dataset_config_str  = toml.dumps(eliminate_none_variable(dataset_config))\n",
        "\n",
        "write_file(config_path, config_str)\n",
        "write_file(prompt_path, prompt_str)\n",
        "write_file(dataset_config_path, dataset_config_str)\n",
        "\n",
        "print(dataset_config_str)\n",
        "print(prompt_str)\n",
        "print(config_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "p_SHtbFwHVl1",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b23f230-8368-4586-ce84-46c32f7f9321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading settings from /content/LoRA/config/config_file.toml...\n",
            "/content/LoRA/config/config_file\n",
            "prepare tokenizer\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 1.27MB/s]\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 823kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 390kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 824/824 [00:00<00:00, 705kB/s]\n",
            "update token length: 225\n",
            "Load dataset config from /content/LoRA/config/dataset_config.toml\n",
            "prepare images.\n",
            "found directory /content/LoRA/train_data contains 0 image files\n",
            "ignore subset with image_dir='/content/LoRA/train_data': no images found / 画像が見つからないためサブセットを無視します\n",
            "found directory /content/LoRA/train_data/content contains 0 image files\n",
            "ignore subset with image_dir='/content/LoRA/train_data/content': no images found / 画像が見つからないためサブセットを無視します\n",
            "found directory /content/LoRA/train_data/content/training_dir contains 0 image files\n",
            "ignore subset with image_dir='/content/LoRA/train_data/content/training_dir': no images found / 画像が見つからないためサブセットを無視します\n",
            "found directory /content/LoRA/train_data/content/training_dir/hitokomoru_dataset contains 0 image files\n",
            "ignore subset with image_dir='/content/LoRA/train_data/content/training_dir/hitokomoru_dataset': no images found / 画像が見つからないためサブセットを無視します\n",
            "found directory /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data contains 0 image files\n",
            "ignore subset with image_dir='/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data': no images found / 画像が見つからないためサブセットを無視します\n",
            "found directory /content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data contains 98 image files\n",
            "980 train images with repeating.\n",
            "0 reg images.\n",
            "no regularization images / 正則化画像が見つかりませんでした\n",
            "[Dataset 0]\n",
            "  batch_size: 2\n",
            "  resolution: (768, 768)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: 320\n",
            "  max_bucket_reso: 1280\n",
            "  bucket_reso_steps: 64\n",
            "  bucket_no_upscale: False\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/LoRA/train_data/content/training_dir/hitokomoru_dataset/train_data/train_data\"\n",
            "    image_count: 98\n",
            "    num_repeats: 10\n",
            "    shuffle_caption: True\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    is_reg: False\n",
            "    class_tokens: None\n",
            "    caption_extension: .txt\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 98/98 [00:00<00:00, 1970.34it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (576, 960), count: 30\n",
            "bucket 1: resolution (640, 896), count: 340\n",
            "bucket 2: resolution (704, 832), count: 290\n",
            "bucket 3: resolution (768, 768), count: 90\n",
            "bucket 4: resolution (832, 704), count: 50\n",
            "bucket 5: resolution (896, 640), count: 90\n",
            "bucket 6: resolution (960, 576), count: 80\n",
            "bucket 7: resolution (1024, 576), count: 10\n",
            "mean ar error (without repeats): 0.03635409916250965\n",
            "prepare accelerator\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Using accelerator 0.15.0 or above.\n",
            "loading model for process 0/1\n",
            "load StableDiffusion checkpoint\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "loading text encoder: <All keys matched successfully>\n",
            "load VAE: /content/vae/animevae.pt\n",
            "additional VAE loaded\n",
            "Replace CrossAttention.forward to use xformers\n",
            "[Dataset 0]\n",
            "caching latents.\n",
            "100% 42/42 [01:09<00:00,  1.65s/it]\n",
            "import network module: networks.lora\n",
            "create LoRA network. base dim (rank): 64, alpha: 64\n",
            "apply LoRA to Conv2d with kernel size (3,3). dim (rank): 64, alpha: 64.0\n",
            "create LoRA for Text Encoder: 138 modules.\n",
            "create LoRA for U-Net: 278 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "prepare optimizer, data loader etc.\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
            "================================================================================\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "use 8-bit AdamW optimizer | {}\n",
            "override steps. steps for 10 epochs is / 指定エポックまでのステップ数: 4900\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 980\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 490\n",
            "  num epochs / epoch数: 10\n",
            "  batch size per device / バッチサイズ: 2\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 4900\n",
            "steps:   0% 0/4900 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinaqruf\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.3 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/LoRA/logs/20230520021347/wandb/run-20230520_021604-utvescpo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgenial-dust-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/linaqruf/hitokomoru_locon_wd_beta3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/linaqruf/hitokomoru_locon_wd_beta3/runs/utvescpo\u001b[0m\n",
            "\n",
            "epoch 1/10\n",
            "steps:  10% 490/4900 [11:25<1:42:49,  1.40s/it, loss=0.412]\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000001.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 490\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (81 > 77). Running this sequence through the model will result in indexing errors\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:41,  1.31it/s]\u001b[A\n",
            "  4% 2/55 [00:01<00:25,  2.05it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:20,  2.48it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:18,  2.75it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:17,  2.91it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:16,  3.05it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:15,  3.13it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.18it/s]\u001b[A\n",
            " 16% 9/55 [00:03<00:14,  3.23it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.25it/s]\u001b[A\n",
            " 22% 12/55 [00:04<00:13,  3.27it/s]\u001b[A\n",
            " 24% 13/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:05<00:11,  3.29it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.29it/s]\u001b[A\n",
            " 35% 19/55 [00:06<00:10,  3.30it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.30it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 40% 22/55 [00:07<00:10,  3.29it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.30it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 45% 25/55 [00:08<00:09,  3.28it/s]\u001b[A\n",
            " 47% 26/55 [00:08<00:08,  3.29it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.29it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.29it/s]\u001b[A\n",
            " 53% 29/55 [00:09<00:07,  3.30it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.29it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.29it/s]\u001b[A\n",
            " 58% 32/55 [00:10<00:06,  3.29it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 64% 35/55 [00:11<00:06,  3.28it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.29it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.28it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:12<00:04,  3.25it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.25it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.25it/s]\u001b[A\n",
            " 76% 42/55 [00:13<00:03,  3.25it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.25it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.25it/s]\u001b[A\n",
            " 82% 45/55 [00:14<00:03,  3.25it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.26it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.26it/s]\u001b[A\n",
            " 87% 48/55 [00:15<00:02,  3.26it/s]\u001b[A\n",
            " 89% 49/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.25it/s]\u001b[A\n",
            " 95% 52/55 [00:16<00:00,  3.25it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:17<00:00,  3.19it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.36it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.34it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.20it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.23it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.27it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.27it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.26it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.25it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.25it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.25it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.25it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.25it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.26it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.25it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.24it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.24it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.25it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.25it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.24it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.24it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:04,  3.25it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.24it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.25it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.25it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.25it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.24it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.25it/s]\u001b[A\n",
            " 89% 49/55 [00:15<00:01,  3.25it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.25it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.25it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.25it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.25it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.26it/s]\n",
            "\n",
            "epoch 2/10\n",
            "steps:  20% 980/4900 [23:25<1:33:43,  1.43s/it, loss=0.406]\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000002.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 980\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.37it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.36it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:15,  3.31it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.29it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.30it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:14,  3.31it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.29it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.30it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:13,  3.31it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.26it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.28it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.29it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.29it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 42% 23/55 [00:06<00:09,  3.29it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.29it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.30it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.29it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.29it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.29it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 65% 36/55 [00:10<00:05,  3.27it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.27it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.26it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.26it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.27it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.28it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.28it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.38it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.35it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:15,  3.28it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.25it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.27it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:14,  3.28it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.24it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.26it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.25it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.26it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.27it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.25it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.25it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.25it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.25it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.24it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.24it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.25it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.26it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.25it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.24it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.25it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.25it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.24it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.25it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.25it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.25it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.25it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:04,  3.24it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.25it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.25it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.25it/s]\u001b[A\n",
            " 89% 49/55 [00:15<00:01,  3.25it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.25it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.26it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.26it/s]\n",
            "\n",
            "epoch 3/10\n",
            "steps:  30% 1470/4900 [35:25<1:22:38,  1.45s/it, loss=0.399]\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000003.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 1470\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.37it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.34it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.18it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.24it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.28it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.25it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.25it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:13,  3.29it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.29it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.30it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.29it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.29it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.28it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.27it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.29it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.29it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.29it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.28it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 65% 36/55 [00:10<00:05,  3.26it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.28it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.28it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.28it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.28it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.28it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.28it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.28it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.41it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.35it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.25it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.27it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.30it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:14,  3.29it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:13,  3.29it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.26it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.26it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.27it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.29it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.27it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.26it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.25it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.25it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.26it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.26it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.25it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.28it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.28it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "\n",
            "epoch 4/10\n",
            "steps:  40% 1960/4900 [47:23<1:11:05,  1.45s/it, loss=0.4]\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000004.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 1960\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.37it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.35it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.15it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.22it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.24it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.24it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.25it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.29it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.28it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.29it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.29it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.29it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.25it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.27it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.28it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.26it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.28it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.27it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.40it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.36it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.17it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.23it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.27it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.25it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.24it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:13,  3.29it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.25it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.26it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.27it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.25it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.27it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.25it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.26it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.25it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.24it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.26it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.26it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.26it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.26it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.26it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.27it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.26it/s]\n",
            "\n",
            "epoch 5/10\n",
            "steps:  50% 2450/4900 [59:22<59:22,  1.45s/it, loss=0.393]\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000005.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 2450\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.35it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.35it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:15,  3.29it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.28it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.29it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:14,  3.28it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:13,  3.29it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.29it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.29it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.28it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.28it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.27it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.27it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.27it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.27it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 65% 36/55 [00:10<00:05,  3.27it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.27it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.26it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.28it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.28it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.28it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.28it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.28it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.28it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.28it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.39it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.34it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.16it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.22it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.25it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.25it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.24it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.25it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.28it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.28it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.25it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.25it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.25it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.26it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.26it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.26it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.25it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.26it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.26it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 89% 49/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.26it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.26it/s]\n",
            "\n",
            "epoch 6/10\n",
            "steps:  60% 2940/4900 [1:11:21<47:34,  1.46s/it, loss=0.391]\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000006.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 2940\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.38it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.33it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.19it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.24it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.28it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.27it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.29it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.29it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.28it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.29it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.29it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.29it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.29it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.29it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.28it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 65% 36/55 [00:10<00:05,  3.26it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.28it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.25it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.28it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.29it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.29it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.29it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.28it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.28it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.28it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.40it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.36it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.19it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.23it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.23it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.23it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.24it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.26it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.28it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.27it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.27it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.27it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.27it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.26it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.28it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.29it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.26it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.27it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "\n",
            "epoch 7/10\n",
            "steps:  70% 3430/4900 [1:23:19<35:42,  1.46s/it, loss=0.39] \n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000007.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 3430\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.36it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.34it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.25it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.27it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.28it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.25it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:13,  3.29it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.30it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.29it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.29it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.29it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.29it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.30it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.28it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.27it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 65% 36/55 [00:10<00:05,  3.26it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.27it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.28it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.28it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.27it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.28it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.40it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.36it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.18it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.23it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.27it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.25it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.24it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.29it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.26it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.26it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.27it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.28it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.26it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.27it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.27it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.25it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.25it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.25it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.27it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.28it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.28it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.28it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.28it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "\n",
            "epoch 8/10\n",
            "steps:  80% 3920/4900 [1:35:18<23:49,  1.46s/it, loss=0.386]\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000008.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 3920\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.39it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.35it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.24it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.28it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:14,  3.29it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.29it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.28it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.27it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.28it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.25it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.24it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.24it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.25it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.24it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.25it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.26it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.25it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.24it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.26it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.27it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.28it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.27it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.42it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.36it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:15,  3.28it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.28it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.29it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:14,  3.29it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.29it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:13,  3.29it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.26it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.26it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.27it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.28it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.27it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.27it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.27it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.26it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 65% 36/55 [00:10<00:05,  3.27it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.28it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.28it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.26it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "\n",
            "epoch 9/10\n",
            "steps:  90% 4410/4900 [1:47:16<11:55,  1.46s/it, loss=0.385]\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3-000009.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 4410\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.36it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.35it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.20it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.29it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.29it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:13,  3.29it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.29it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.30it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.27it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.25it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.25it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.27it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.28it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.29it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:06,  3.29it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.29it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.29it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 65% 36/55 [00:10<00:05,  3.29it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.28it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.29it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.29it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.29it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.26it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.26it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.28it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.28it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.27it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.37it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.33it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.19it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.23it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.25it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.25it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.28it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.24it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.27it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.26it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.28it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.27it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.28it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.27it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.26it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.27it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.26it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.28it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.28it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.26it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.27it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.26it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.26it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "\n",
            "epoch 10/10\n",
            "steps: 100% 4900/4900 [1:59:14<00:00,  1.46s/it, loss=0.384]generating sample images at step / サンプル画像生成 ステップ: 4900\n",
            "prompt: masterpiece, best quality, 1girl, solo, long hair, blush, bangs, simple background, hair ornament, long sleeves, white background, ribbon, hair ribbon, upper body, pink hair, braid, flower, parted lips, japanese clothes, hair flower, kimono, sleeves past wrists, single braid, looking away, bug, red flower, butterfly, purple flower, black kimono\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:16,  3.37it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.35it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.18it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.23it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.23it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.23it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.26it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.25it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.24it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.28it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.26it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.27it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.25it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.26it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:11,  3.27it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.25it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.26it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.26it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.27it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.27it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.29it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.29it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.29it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:06,  3.29it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 65% 36/55 [00:11<00:05,  3.28it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.27it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.28it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.28it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.28it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.28it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.29it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.29it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.26it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "prompt: masterpiece, best quality, 1girl, solo, looking at viewer, smile, short hair, bangs, simple background, red eyes, long sleeves, hat, white background, dress, ribbon, hair between eyes, jewelry, closed mouth, flower, cowboy shot, frills, one eye closed, wings, nail polish, white dress, red bow, bracelet, red ribbon, fingernails, sash, ascot, capelet, white headwear, mob cap, hat ribbon, bat wings, white flower, slit pupils, red nails, bright pupils, white pupils, hat flower, white capelet, white ascot, red sash, frilled capelet, remilia scarlet\n",
            "negative_prompt: (worst quality, low quality:1.4)\n",
            "height: 768\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/55 [00:00<00:15,  3.38it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:15,  3.35it/s]\u001b[A\n",
            "  5% 3/55 [00:00<00:16,  3.23it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:15,  3.26it/s]\u001b[A\n",
            "  9% 5/55 [00:01<00:15,  3.28it/s]\u001b[A\n",
            " 11% 6/55 [00:01<00:15,  3.27it/s]\u001b[A\n",
            " 13% 7/55 [00:02<00:14,  3.25it/s]\u001b[A\n",
            " 15% 8/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 16% 9/55 [00:02<00:14,  3.27it/s]\u001b[A\n",
            " 18% 10/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 20% 11/55 [00:03<00:13,  3.24it/s]\u001b[A\n",
            " 22% 12/55 [00:03<00:13,  3.26it/s]\u001b[A\n",
            " 24% 13/55 [00:03<00:12,  3.25it/s]\u001b[A\n",
            " 25% 14/55 [00:04<00:12,  3.26it/s]\u001b[A\n",
            " 27% 15/55 [00:04<00:12,  3.28it/s]\u001b[A\n",
            " 29% 16/55 [00:04<00:11,  3.28it/s]\u001b[A\n",
            " 31% 17/55 [00:05<00:11,  3.28it/s]\u001b[A\n",
            " 33% 18/55 [00:05<00:11,  3.29it/s]\u001b[A\n",
            " 35% 19/55 [00:05<00:10,  3.29it/s]\u001b[A\n",
            " 36% 20/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 38% 21/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 40% 22/55 [00:06<00:10,  3.29it/s]\u001b[A\n",
            " 42% 23/55 [00:07<00:09,  3.28it/s]\u001b[A\n",
            " 44% 24/55 [00:07<00:09,  3.29it/s]\u001b[A\n",
            " 45% 25/55 [00:07<00:09,  3.29it/s]\u001b[A\n",
            " 47% 26/55 [00:07<00:08,  3.29it/s]\u001b[A\n",
            " 49% 27/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 51% 28/55 [00:08<00:08,  3.28it/s]\u001b[A\n",
            " 53% 29/55 [00:08<00:07,  3.28it/s]\u001b[A\n",
            " 55% 30/55 [00:09<00:07,  3.28it/s]\u001b[A\n",
            " 56% 31/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 58% 32/55 [00:09<00:07,  3.27it/s]\u001b[A\n",
            " 60% 33/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 62% 34/55 [00:10<00:06,  3.27it/s]\u001b[A\n",
            " 64% 35/55 [00:10<00:06,  3.28it/s]\u001b[A\n",
            " 65% 36/55 [00:10<00:05,  3.29it/s]\u001b[A\n",
            " 67% 37/55 [00:11<00:05,  3.29it/s]\u001b[A\n",
            " 69% 38/55 [00:11<00:05,  3.28it/s]\u001b[A\n",
            " 71% 39/55 [00:11<00:04,  3.27it/s]\u001b[A\n",
            " 73% 40/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 75% 41/55 [00:12<00:04,  3.27it/s]\u001b[A\n",
            " 76% 42/55 [00:12<00:03,  3.27it/s]\u001b[A\n",
            " 78% 43/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 80% 44/55 [00:13<00:03,  3.26it/s]\u001b[A\n",
            " 82% 45/55 [00:13<00:03,  3.27it/s]\u001b[A\n",
            " 84% 46/55 [00:14<00:02,  3.27it/s]\u001b[A\n",
            " 85% 47/55 [00:14<00:02,  3.28it/s]\u001b[A\n",
            " 87% 48/55 [00:14<00:02,  3.29it/s]\u001b[A\n",
            " 89% 49/55 [00:14<00:01,  3.28it/s]\u001b[A\n",
            " 91% 50/55 [00:15<00:01,  3.28it/s]\u001b[A\n",
            " 93% 51/55 [00:15<00:01,  3.27it/s]\u001b[A\n",
            " 95% 52/55 [00:15<00:00,  3.27it/s]\u001b[A\n",
            " 96% 53/55 [00:16<00:00,  3.26it/s]\u001b[A\n",
            " 98% 54/55 [00:16<00:00,  3.27it/s]\u001b[A\n",
            "100% 55/55 [00:16<00:00,  3.27it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   loss/average █▇▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▂▃▂▃▂▃▂▂▂▂▂▂▁▂▂▂▂▁▁▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   loss/current ▅▄█▇▅▇▄▅▆▅▅▅▇▆▄▅▆▄▆▆▃▅▆▂▆▅█▇▁▃▅▇▆▅▇▄▄▁▅▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: lr/textencoder ███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        lr/unet ███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   loss/average 0.38374\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   loss/current 0.45005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: lr/textencoder 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        lr/unet 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgenial-dust-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/linaqruf/hitokomoru_locon_wd_beta3/runs/utvescpo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 20 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/content/LoRA/logs/20230520021347/wandb/run-20230520_021604-utvescpo/logs\u001b[0m\n",
            "\n",
            "saving checkpoint: /content/LoRA/output/hitokomoru_locon_wd_beta3.safetensors\n",
            "model saved.\n",
            "steps: 100% 4900/4900 [2:00:02<00:00,  1.47s/it, loss=0.384]\n"
          ]
        }
      ],
      "source": [
        "#@title ## 4.4. Start Training\n",
        "import os\n",
        "import toml\n",
        "\n",
        "#@markdown Check your config here if you want to edit something: \n",
        "#@markdown - `sample_prompt` : /content/LoRA/config/sample_prompt.toml\n",
        "#@markdown - `config_file` : /content/LoRA/config/config_file.toml\n",
        "#@markdown - `dataset_config` : /content/LoRA/config/dataset_config.toml\n",
        "\n",
        "#@markdown You can import config from another session if you want.\n",
        "\n",
        "sample_prompt   = \"/content/LoRA/config/sample_prompt.toml\" #@param {type:'string'}\n",
        "config_file     = \"/content/LoRA/config/config_file.toml\" #@param {type:'string'}\n",
        "dataset_config  = \"/content/LoRA/config/dataset_config.toml\" #@param {type:'string'}\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def train(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : accelerate_config,\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\"  : sample_prompt if os.path.exists(sample_prompt) else None,\n",
        "    \"dataset_config\"  : dataset_config,\n",
        "    \"config_file\"     : config_file,\n",
        "    \"wandb_api_key\"   : wandb_api_key if wandb_api_key else None,\n",
        "}\n",
        "\n",
        "accelerate_args = train(accelerate_conf)\n",
        "train_args = train(train_conf)\n",
        "\n",
        "final_args = f\"accelerate launch {accelerate_args} train_network.py {train_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reMcN0bM_o53"
      },
      "source": [
        "# V. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FKBrTDPrcNjP"
      },
      "outputs": [],
      "source": [
        "# @title ## 5.1. Inference\n",
        "%store -r\n",
        "import toml\n",
        "\n",
        "# @markdown Currently, `[\"LoCon\", \"LoHa\", \"IA3\", \"LoKR\", \"DyLoRA_Lycoris\"]` are not supported. Please run `Portable Web UI` instead\n",
        "network_weight = \"/content/LoRA/output/hitokomoru.safetensors\"  # @param {'type':'string'}\n",
        "network_mul = 0.7  # @param {type:\"slider\", min:-1, max:2, step:0.05}\n",
        "prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\"  # @param {type: \"string\"}\n",
        "negative = \"(worst quality, low quality:1.4)\"  # @param {type: \"string\"}\n",
        "\n",
        "final_prompt = f\"{prompt} --n {negative}\"\n",
        "config_file = \"/content/LoRA/config/config_file.toml\"\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def get_key(config, subset, key):\n",
        "    return config.get(key) or config.get(subset, {}).get(key)\n",
        "\n",
        "config_str = read_file(config_file)\n",
        "config = toml.loads(config_str)\n",
        "\n",
        "network_module = get_key(config, \"additional_network_arguments\", \"network_module\")\n",
        "clip_skip = get_key(config, \"training_arguments\", \"clip_skip\")\n",
        "\n",
        "config = {\n",
        "    \"v2\": v2,\n",
        "    \"v_parameterization\": v_parameterization,\n",
        "    \"network_module\": network_module if network_module not in [\"LoCon\", \"LoHa\", \"IA3\", \"LoKR\"] else None,\n",
        "    \"network_weight\": network_weight,\n",
        "    \"network_mul\": float(network_mul),\n",
        "    \"network_args\": None,\n",
        "    \"ckpt\": model_path,\n",
        "    \"outdir\": \"/content/tmp\",\n",
        "    \"xformers\": True,\n",
        "    \"vae\": vae_path,\n",
        "    \"fp16\": True,\n",
        "    \"W\": 512,\n",
        "    \"H\": 768,\n",
        "    \"seed\": None,\n",
        "    \"scale\": 7,\n",
        "    \"sampler\": \"k_dpm_2_a\",\n",
        "    \"steps\": 28,\n",
        "    \"max_embeddings_multiples\": 3,\n",
        "    \"batch_size\": 4,\n",
        "    \"images_per_prompt\": 4,\n",
        "    \"clip_skip\": clip_skip if not v2 else None,\n",
        "    \"prompt\": final_prompt,\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python gen_img_diffusers.py {args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dglQfu3A0oaj"
      },
      "outputs": [],
      "source": [
        "#@title ## 5.2. Launch Portable Web UI\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import time\n",
        "import json\n",
        "from google.colab import drive\n",
        "from datetime import timedelta\n",
        "from subprocess import getoutput\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "webui_dir       = os.path.join(root_dir, \"cagliostro-colab-ui\")\n",
        "tmp_dir         = os.path.join(root_dir, \"tmp\")\n",
        "patches_dir     = os.path.join(root_dir, \"patches\")\n",
        "deps_dir        = os.path.join(root_dir, \"deps\")\n",
        "extensions_dir  = os.path.join(webui_dir, \"extensions\")\n",
        "control_dir     = os.path.join(webui_dir, \"models/ControlNet\")\n",
        "\n",
        "webui_models_dir  = os.path.join(webui_dir, \"models/Stable-diffusion\")\n",
        "webui_lora_dir    = os.path.join(webui_dir, \"models/Lora\")\n",
        "webui_vaes_dir    = os.path.join(webui_dir, \"models/VAE\")\n",
        "\n",
        "control_net_max_models_num = 2\n",
        "theme = \"minimal_orange\"\n",
        "\n",
        "default_prompt      = \"masterpiece, best quality,\"\n",
        "default_neg_prompt  = \"(worst quality, low quality:1.4)\"\n",
        "default_sampler     = \"DPM++ 2M Karras\"\n",
        "default_steps       = 20\n",
        "default_width       = 512\n",
        "default_height      = 768\n",
        "default_denoising_strength = 0.55\n",
        "default_cfg_scale   = 7\n",
        "\n",
        "config_file       = os.path.join(webui_dir, \"config.json\")\n",
        "ui_config_file    = os.path.join(webui_dir, \"ui-config.json\")\n",
        "webui_style_path  = os.path.join(webui_dir, \"style.css\")\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "for dir in [patches_dir, deps_dir]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "package_url = [\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/anapnoe-webui.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/anapnoe-webui-deps.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/anapnoe-webui-cache.tar.lz4\",\n",
        "]\n",
        "\n",
        "def pre_download(desc):\n",
        "    for package in tqdm(package_url, desc=desc):\n",
        "        with capture.capture_output() as cap:\n",
        "            package_name = os.path.basename(package)\n",
        "            !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {root_dir} -o {package_name} {package}\n",
        "            if package_name == f\"anapnoe-webui-deps.tar.lz4\":\n",
        "                !tar -xI lz4 -f {package_name} --overwrite-dir --directory=/usr/local/lib/python3.10/dist-packages/\n",
        "            else:\n",
        "                !tar -xI lz4 -f {package_name} --directory=/\n",
        "            os.remove(package_name)\n",
        "            del cap\n",
        "\n",
        "    if os.path.exists(\"/usr/local/lib/python3.10/dist-packages/ffmpy-0.3.0.dist-info\"):\n",
        "        shutil.rmtree(\"/usr/local/lib/python3.10/dist-packages/ffmpy-0.3.0.dist-info\")\n",
        "\n",
        "    s = getoutput(\"nvidia-smi\")\n",
        "    with capture.capture_output() as cap:\n",
        "        if not \"T4\" in s:\n",
        "            !pip uninstall -y xformers\n",
        "            !pip install -q xformers==0.0.18\n",
        "        del cap\n",
        "\n",
        "def read_config(filename):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"r\") as f:\n",
        "          config = json.load(f)\n",
        "    else:\n",
        "        with open(filename, 'r') as f:\n",
        "          config = f.read()\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(config, f, indent=4)\n",
        "    else:\n",
        "        with open(filename, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(config)\n",
        "\n",
        "def open_theme(filename):\n",
        "    themes_folder = os.path.join(webui_dir, \"extensions-builtin/sd_theme_editor/themes\")\n",
        "    themes_file = os.path.join(themes_folder, f\"{filename}.css\")\n",
        "    webui_style_path = os.path.join(webui_dir, \"style.css\")\n",
        "\n",
        "    style_config = read_config(webui_style_path)\n",
        "    style_css_contents = style_config.split(\"/*BREAKPOINT_CSS_CONTENT*/\")[1]\n",
        "\n",
        "    theme_config = read_config(themes_file)\n",
        "    style_data = \":host{\" + theme_config + \"}\" + \"/*BREAKPOINT_CSS_CONTENT*/\" + style_css_contents\n",
        "    write_config(webui_style_path, style_data)\n",
        "\n",
        "def change_config(filename):\n",
        "    config = read_config(filename)\n",
        "    config[\"outdir_txt2img_samples\"] = os.path.join(tmp_dir, \"outputs/txt2img-images\")\n",
        "    config[\"outdir_img2img_samples\"] = os.path.join(tmp_dir, \"outputs/img2img-images\")\n",
        "    config[\"outdir_extras_samples\"] = os.path.join(tmp_dir, \"outputs/extras-images\")\n",
        "    config[\"outdir_txt2img_grids\"] = os.path.join(tmp_dir, \"outputs/txt2img-grids\")\n",
        "    config[\"outdir_img2img_grids\"] = os.path.join(tmp_dir, \"outputs/img2img-grids\")\n",
        "    config[\"outdir_save\"] = os.path.join(tmp_dir, \"log/images\")\n",
        "    config[\"control_net_max_models_num\"] = control_net_max_models_num\n",
        "    config[\"control_net_models_path\"] = control_dir\n",
        "    config[\"control_net_allow_script_control\"] = True\n",
        "    config[\"additional_networks_extra_lora_path\"] = output_dir\n",
        "    config[\"CLIP_stop_at_last_layers\"] = 2\n",
        "    config[\"eta_noise_seed_delta\"] = 0\n",
        "    config[\"show_progress_every_n_steps\"] = 10\n",
        "    config[\"show_progressbar\"] = True\n",
        "    config[\"quicksettings_list\"] = [\n",
        "        \"sd_model_checkpoint\", \n",
        "        \"sd_vae\", \n",
        "        \"CLIP_stop_at_last_layers\", \n",
        "        \"use_old_karras_scheduler_sigmas\", \n",
        "        \"always_discard_next_to_last_sigma\"\n",
        "        ]\n",
        "    write_config(filename, config)\n",
        "\n",
        "def change_ui_config(filename):\n",
        "    config = read_config(filename)\n",
        "    config[\"txt2img/Prompt/value\"] = default_prompt\n",
        "    config[\"txt2img/Negative prompt/value\"] = default_neg_prompt\n",
        "    config[\"txt2img/Sampling method/value\"] = default_sampler\n",
        "    config[\"txt2img/Sampling steps/value\"] = default_steps\n",
        "    config[\"txt2img/Width/value\"] = default_width\n",
        "    config[\"txt2img/Height/value\"] = default_height\n",
        "    config[\"txt2img/Upscaler/value\"] = \"Latent (nearest-exact)\"\n",
        "    config[\"txt2img/Denoising strength/value\"] = default_denoising_strength\n",
        "    config[\"txt2img/CFG Scale/value\"] = default_cfg_scale\n",
        "    config[\"img2img/Prompt/value\"] = default_prompt\n",
        "    config[\"img2img/Negative prompt/value\"] = default_neg_prompt\n",
        "    config[\"img2img/Sampling method/value\"] = default_sampler\n",
        "    config[\"img2img/Sampling steps/value\"] = default_steps\n",
        "    config[\"img2img/Width/value\"] = default_width\n",
        "    config[\"img2img/Height/value\"] = default_height\n",
        "    config[\"img2img/Denoising strength/value\"] = default_denoising_strength\n",
        "    config[\"img2img/CFG Scale/value\"] = default_cfg_scale\n",
        "    write_config(filename, config)\n",
        "\n",
        "def update_extensions():\n",
        "    start_time = time.time()\n",
        "    extensions_updated = []\n",
        "    extensions_list = os.listdir(extensions_dir)\n",
        "    with tqdm(\n",
        "        total=len(extensions_list) - 1,\n",
        "        desc=\"\u001b[1;32mUpdating extensions\",\n",
        "        mininterval=0,\n",
        "    ) as pbar:\n",
        "        for dir in os.listdir(extensions_dir):\n",
        "            if os.path.isdir(os.path.join(extensions_dir, dir)):\n",
        "                os.chdir(os.path.join(extensions_dir, dir))\n",
        "                try:\n",
        "                    with capture.capture_output() as cap:\n",
        "                        !git fetch origin\n",
        "                        !git pull\n",
        "                except Exception as e:\n",
        "                    print(f\"\u001b[1;32mAn error occurred while updating {dir}: {e}\")\n",
        "\n",
        "                output = cap.stdout.strip()\n",
        "                if \"Already up to date.\" not in output:\n",
        "                    extensions_updated.append(dir)\n",
        "                pbar.update(1)\n",
        "\n",
        "    for ext in extensions_updated:\n",
        "        print(f\"\u001b[1;32m- {ext} updated to new version\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = int(end_time - start_time)\n",
        "\n",
        "    if elapsed_time < 60:\n",
        "        print(f\"\u001b[1;32mAll extensions are up to date. Took {elapsed_time} sec\")\n",
        "    else:\n",
        "        mins, secs = divmod(elapsed_time, 60)\n",
        "        print(f\"\u001b[1;32mAll extensions are up to date. Took {mins} mins {secs} sec\")\n",
        "\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(\"\u001b[1;32mInstalling...\")\n",
        "\n",
        "    if not os.path.exists(webui_dir):\n",
        "        desc = \"\u001b[1;32mUnpacking Webui\"\n",
        "        pre_download(desc)\n",
        "    else:\n",
        "        print(\"\u001b[1;32mAlready installed, skipping...\")\n",
        "\n",
        "    with capture.capture_output() as cap:\n",
        "        os.chdir(os.path.join(webui_dir, \"repositories/stable-diffusion-stability-ai\"))\n",
        "        !git apply {patches_dir}/stablediffusion-lowram.patch\n",
        "        !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" {repo_dir}/modules/sd_models.py\n",
        "        !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' {repo_dir}/webui.py\n",
        "        !sed -i \"s@map_location='cpu'@map_location='cuda'@\" {repo_dir}/modules/extras.py\n",
        "        del cap\n",
        "      \n",
        "    end_time = time.time()\n",
        "    elapsed_time = int(end_time - start_time)\n",
        "\n",
        "    change_config(config_file)\n",
        "    change_ui_config(ui_config_file)\n",
        "    open_theme(theme)\n",
        "\n",
        "    if elapsed_time < 60:\n",
        "        print(f\"\u001b[1;32mFinished unpacking. Took {elapsed_time} sec\")\n",
        "    else:\n",
        "        mins, secs = divmod(elapsed_time, 60)\n",
        "        print(f\"\u001b[1;32mFinished unpacking. Took {mins} mins {secs} sec\")\n",
        "\n",
        "    update_extensions()\n",
        "\n",
        "    #@markdown > Get <b>your</b> `ngrok_token` [here](https://dashboard.ngrok.com/get-started/your-authtoken) \n",
        "    ngrok_token = \"\" #@param {type: 'string'}\n",
        "    ngrok_region = \"ap\" #@param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "    os.chdir(webui_dir)\n",
        "\n",
        "    print(\"\u001b[1;32m\")\n",
        "\n",
        "    config = {\n",
        "        \"enable-insecure-extension-access\": True,\n",
        "        \"disable-safe-unpickle\"           : True,\n",
        "        \"multiple\"                        : True if not ngrok_token else False,\n",
        "        \"share\"                           : True if not ngrok_token else False,\n",
        "        \"no-half-vae\"                     : True,\n",
        "        \"lowram\"                          : True,\n",
        "        \"gradio-queue\"                    : True,\n",
        "        \"no-hashing\"                      : True,\n",
        "        \"disable-console-progressbars\"    : True,\n",
        "        \"ngrok\"                           : ngrok_token if ngrok_token else None,\n",
        "        \"ngrok-region\"                    : ngrok_region if ngrok_token else None,\n",
        "        \"xformers\"                        : True,\n",
        "        \"opt-sub-quad-attention\"          : True,\n",
        "        \"opt-channelslast\"                : True,\n",
        "        \"theme\"                           : \"dark\",\n",
        "        \"listen\"                          : True,\n",
        "        \"ckpt-dir\"                        : pretrained_model,\n",
        "        \"vae-dir\"                         : vae_dir,\n",
        "        \"lora-dir\"                        : output_dir,\n",
        "        \"lyco-dir\"                        : output_dir,        \n",
        "    }\n",
        "\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    final_args = f\"python launch.py {args}\"\n",
        "\n",
        "    os.chdir(webui_dir)\n",
        "    !{final_args}\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyIl9BhNXKUq"
      },
      "source": [
        "# VI. Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8YlP0cNQyujy"
      },
      "outputs": [],
      "source": [
        "# @title ## 6.1. Huggingface Hub config\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "# @markdown Login to Huggingface Hub\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
        "orgs_name = \"\"  # @param{type:\"string\"}\n",
        "# @markdown If your model/dataset repo does not exist, it will automatically create it.\n",
        "model_name = \"\"  # @param{type:\"string\"}\n",
        "dataset_name = \"\"  # @param{type:\"string\"}\n",
        "make_private = False  # @param{type:\"boolean\"}\n",
        "\n",
        "def authenticate(write_token):\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "    api = HfApi()\n",
        "    return api.whoami(write_token), api\n",
        "\n",
        "def create_repo(api, user, orgs_name, repo_name, repo_type, make_private=False):\n",
        "    global model_repo\n",
        "    global datasets_repo\n",
        "    \n",
        "    if orgs_name == \"\":\n",
        "        repo_id = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "    else:\n",
        "        repo_id = orgs_name + \"/\" + repo_name.strip()\n",
        "\n",
        "    try:\n",
        "        validate_repo_id(repo_id)\n",
        "        api.create_repo(repo_id=repo_id, repo_type=repo_type, private=make_private)\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' didn't exist, creating repo\")\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' exists, skipping create repo\")\n",
        "    \n",
        "    if repo_type == \"model\":\n",
        "        model_repo = repo_id\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/{repo_id}\\n\")\n",
        "    else:\n",
        "        datasets_repo = repo_id\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/datasets/{repo_id}\\n\")\n",
        "\n",
        "user, api = authenticate(write_token)\n",
        "\n",
        "if model_name:\n",
        "    create_repo(api, user, orgs_name, model_name, \"model\", make_private)\n",
        "if dataset_name:\n",
        "    create_repo(api, user, orgs_name, dataset_name, \"dataset\", make_private)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8HpOZOglBJTz"
      },
      "outputs": [],
      "source": [
        "# @title ## 6.2. Upload LoRA to Huggingface\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "\n",
        "%store -r\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be uploaded to model repo\n",
        "model_path = \"/content/LoRA/output\"  # @param {type :\"string\"}\n",
        "path_in_repo = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown Now you can save your config file for future use\n",
        "config_path = \"/content/LoRA/config\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "    commit_message = f\"feat: upload {project_name} lora model\"\n",
        "\n",
        "def upload_to_hf(model_path, is_folder, is_config):\n",
        "    path_obj = Path(model_path)\n",
        "    trained_model = path_obj.parts[-1]\n",
        "\n",
        "    if path_in_repo:\n",
        "        trained_model = path_in_repo\n",
        "\n",
        "    if is_config:\n",
        "        trained_model = f\"{project_name}_config\"\n",
        "\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/{model_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    if is_folder:\n",
        "        api.upload_folder(\n",
        "            folder_path=model_path,\n",
        "            path_in_repo=trained_model,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/{model_repo}/tree/main\\n\")\n",
        "    else:\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=model_path,\n",
        "            path_in_repo=trained_model,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/{model_repo}/blob/main/{trained_model}\\n\")\n",
        "\n",
        "def upload():\n",
        "    is_model_file = model_path.endswith((\".ckpt\", \".safetensors\", \".pt\"))\n",
        "    upload_to_hf(model_path, not is_model_file, False)\n",
        "\n",
        "    if config_path:\n",
        "        upload_to_hf(config_path, True, True)\n",
        "\n",
        "upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IW-hS9jnmf-E"
      },
      "outputs": [],
      "source": [
        "# @title ## 6.3. Upload Dataset to Huggingface\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be compressed to zip and  uploaded to datasets repo, leave it empty if not necessary\n",
        "train_data_path = \"/content/LoRA/train_data\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/LoRA/logs\"  # @param {type :\"string\"}\n",
        "\n",
        "tmp_dataset = f\"/content/LoRA/{project_name}_dataset\" if project_name else \"/content/LoRA/tmp_dataset\"\n",
        "tmp_train_data = f\"{tmp_dataset}/train_data\"\n",
        "dataset_zip = f\"{tmp_dataset}.zip\"\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "    commit_message = f\"feat: upload {project_name} dataset and logs\"\n",
        "\n",
        "os.makedirs(tmp_dataset, exist_ok=True)\n",
        "os.makedirs(tmp_train_data, exist_ok=True)\n",
        "\n",
        "def upload_dataset(dataset_path, is_zip):\n",
        "    path_obj = Path(dataset_path)\n",
        "    dataset_name = path_obj.parts[-1]\n",
        "\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/{datasets_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    if is_zip:\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=dataset_path,\n",
        "            path_in_repo=dataset_name,\n",
        "            repo_id=datasets_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/datasets/{datasets_repo}/blob/main/{dataset_name}\\n\")\n",
        "    else:\n",
        "        api.upload_folder(\n",
        "            folder_path=dataset_path,\n",
        "            path_in_repo=dataset_name,\n",
        "            repo_id=datasets_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/datasets/{datasets_repo}/tree/main/{dataset_name}\\n\")\n",
        "\n",
        "def zip_file(folder_path):\n",
        "    zip_path = f\"{folder_path}.zip\"\n",
        "    with zipfile.ZipFile(zip_path, \"w\") as zip_file:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                zip_file.write(os.path.join(root, file))\n",
        "\n",
        "def move(src_path, dst_path, move_metadata):\n",
        "    metadata_files = [\n",
        "        \"meta_cap.json\",\n",
        "        \"meta_cap_dd.json\",\n",
        "        \"meta_lat.json\",\n",
        "        \"meta_clean.json\",\n",
        "        \"meta_final.json\",\n",
        "    ]\n",
        "\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "    if move_metadata:\n",
        "        parent_meta_path = os.path.dirname(src_path)\n",
        "\n",
        "        for filename in os.listdir(parent_meta_path):\n",
        "            file_path = os.path.join(parent_meta_path, filename)\n",
        "            if filename in metadata_files:\n",
        "                shutil.move(file_path, dst_path)\n",
        "\n",
        "def upload():\n",
        "    if train_data_path:\n",
        "        move(train_data_path, tmp_train_data, False)\n",
        "        zip_file(tmp_dataset)\n",
        "        upload_dataset(dataset_zip, True)\n",
        "        os.remove(dataset_zip)\n",
        "    if logs_path:\n",
        "        upload_dataset(logs_path, False)\n",
        "\n",
        "upload()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}